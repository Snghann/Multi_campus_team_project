{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d1c61-fbad-4571-84c0-16586c9120f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 현재 페이지\n",
    "page_num = 1\n",
    "page_ctl = 3\n",
    "\n",
    "write_dt_lst = []\n",
    "item_nm_lst = []\n",
    "content_lst = []\n",
    "\n",
    "\n",
    "# 날짜 \n",
    "date_cut = (datetime.now() - timedelta(days = 365)).strftime('%Y%m%d')\n",
    "\n",
    "while True :\n",
    "    print(f'start : {page_num} page 수집 중, page_ctl:{page_ctl}')\n",
    "    \n",
    "    # 1. 셀레니움으로 html가져오기\n",
    "    html_source = driver.page_source\n",
    "    \n",
    "    # 2. bs4로 html 파싱\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # 3. 리뷰 정보 가져오기\n",
    "    reviews = soup.findAll('li', {'class': 'BnwL_cs1av'})\n",
    "\n",
    "\n",
    "    # 4. 한페이지 내에서 수집 가능한 리뷰 리스트에 저장\n",
    "    for review in range(len(reviews)):\n",
    "\n",
    "        # 4-1.리뷰작성일자 수집\n",
    "        write_dt_raw = reviews[review].findAll('span' ,{'class' : '_2L3vDiadT9'})[0].get_text()\n",
    "        write_dt = datetime.strptime(write_dt_raw, '%y.%m.%d.').strftime('%Y%m%d')\n",
    "\n",
    "        # 4-2.상품명 수집\n",
    "        # 4-2-(1) 상품명이 포함된 css 선택자 입력 \n",
    "        item_nm_info_raw = reviews[review].findAll('div', {'class' : '_2FXNMst_ak'})[0].get_text()\n",
    "\n",
    "        # 4-2-(2) re.sub() 를 활용해 dl class=\"XbGQRlzveO\"부분부터 추출한 문장을 공백으로 대체\n",
    "        item_nm_info_for_del = reviews[review].findAll('div', {'class' : '_2FXNMst_ak'})[0].find('dl', {'class' : 'XbGQRlzveO'}).get_text()\n",
    "\n",
    "        # 4-2-(3) re.sub(pattern, replacement, string) : string에서 pattern에 해당하는 부분을 replacement로 모두 대체\n",
    "        item_nm_info= re.sub(item_nm_info_for_del, '', item_nm_info_raw)\n",
    "\n",
    "        # 4-2-(4) find() : 문자열 순서 (인덱스) 반환 : find()를 활용해 '제품 선택 : '이 나오는 인덱스 반환\n",
    "        str_start_idx = re.sub(item_nm_info_for_del, '', item_nm_info_raw).find('제품 선택: ')\n",
    "\n",
    "        # 4-2-(5) 제품명만 추출. strip(): 공백 제거 \n",
    "        item_nm = item_nm_info[str_start_idx + 6:].strip()\n",
    "\n",
    "\n",
    "        # 4-3. 리뷰내용 수집\n",
    "        review_content_raw = reviews[review].findAll('div', {'class' : '_1kMfD5ErZ6'})[0].find('span', {'class' : '_2L3vDiadT9'}).get_text()\n",
    "        review_content = re.sub(' +', ' ',re.sub('\\n',' ',review_content_raw ))\n",
    "\n",
    "        # 4-4. 수집데이터 저장\n",
    "        write_dt_lst.append(write_dt)\n",
    "        item_nm_lst.append(item_nm)\n",
    "        content_lst.append(review_content)\n",
    " \n",
    "    # 리뷰 수집일자 기준 데이터 확인(최근 1년치만 수집)\n",
    "    if write_dt_lst[-1] < date_cut :\n",
    "        break\n",
    "        \n",
    "    # page 이동\n",
    "    driver.find_element(By.CSS_SELECTOR,f'#REVIEW > div > div._2LvIMaBiIO > div._2g7PKvqCKe > div > div > a:nth-child({page_ctl})').click()    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # 셀레니움으로 html가져오기\n",
    "    html_source = driver.page_source\n",
    "    \n",
    "    # bs4로 html 파싱\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    time.sleep(0.5)\n",
    " \n",
    "    page_num += 1\n",
    "    page_ctl += 1\n",
    " \n",
    "    if page_num % 10 == 1 :\n",
    "        page_ctl = 3\n",
    "print('done') \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be984b00-f8e8-4670-a0a5-b424de49aff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (4.34.2)\n",
      "Requirement already satisfied: webdriver_manager in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: urllib3~=2.5.0 in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio~=0.30.0 in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.12.2 in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from selenium) (2025.7.14)\n",
      "Requirement already satisfied: typing_extensions~=4.14.0 in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from selenium) (4.14.1)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from webdriver_manager) (1.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from webdriver_manager) (24.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ksp45\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (3.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ecd8dc2-c263-479b-aa25-b1b51243719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc29df1-4fd8-459c-9846-33e3131895af",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()  # 크롬 옵션 객체 생성\n",
    "options.add_argument(\"window-size-1920x1080\")  # 전체화면\n",
    "options.add_argument(\"disable-gpu\")\n",
    "options.add_argument(\"disable-infobars\")\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument(\"--no-sandbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6e4ff5-d9ca-4072-8ccd-f3bc2191324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = \"C:/Users/ksp45/Desktop/chromedriver-win64/chromedriver-win64/chromedriver.exe\"\n",
    "service = Service(executable_path = chrome_driver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "d9b8c3eb-56f7-4f1d-a257-8922bdd837ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service = service, options = options)\n",
    "driver.implicitly_wait(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "f55770e6-4e31-40fa-8656-99d5c244a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://smartstore.naver.com/ivysmall/products/8495493369\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "2ada7f20-8501-49e5-86f0-ecb6ca59d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "b4daee83-3cbc-465a-96a0-38cc575efcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.CSS_SELECTOR, \"#content > div > div._3CTsMZymJs > div:nth-child(3) > div._27jmWaPaKy > ul > li:nth-child(2) > a\").click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "16b65210-da90-42db-8af6-6a6dbaedc352",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.CSS_SELECTOR, \"#REVIEW > div > div._2LvIMaBiIO > div._3aC7jlfVdk > div._1txuie7UTH > ul > li:nth-child(2) > a\").click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "07f3b5fd-adbc-4464-b398-f63c2c99f116",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start : 1 page 수집 중, page_ctl:3\n",
      "start : 2 page 수집 중, page_ctl:4\n",
      "start : 3 page 수집 중, page_ctl:5\n",
      "start : 4 page 수집 중, page_ctl:6\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 현재 페이지\n",
    "page_num = 1\n",
    "page_ctl = 3\n",
    "\n",
    "write_dt_lst = []\n",
    "item_nm_lst = []\n",
    "content_lst = []\n",
    "\n",
    "# 날짜 \n",
    "date_cut = (datetime.now() - timedelta(days=365)).strftime('%Y%m%d')\n",
    "\n",
    "while True:\n",
    "    if page_num == 26:\n",
    "        print(\"500개 수집 완료\")\n",
    "        break\n",
    "        \n",
    "    print(f'start : {page_num} page 수집 중, page_ctl:{page_ctl}')\n",
    "    \n",
    "    # 1. 셀레니움으로 html 가져오기\n",
    "    html_source = driver.page_source\n",
    "\n",
    "    # 2. bs4로 html 파싱\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # 3. 리뷰 정보 가져오기\n",
    "    reviews = soup.findAll('li', {'class': 'BnwL_cs1av'})\n",
    "\n",
    "    # 4. 한 페이지 내에서 수집 가능한 리뷰 리스트에 저장\n",
    "    for review in range(len(reviews)):\n",
    "        try:\n",
    "            # 4-1. 리뷰 작성일자 수집\n",
    "            write_dt_raw = reviews[review].findAll('span', {'class': '_2L3vDiadT9'})[0].get_text()\n",
    "            write_dt = datetime.strptime(write_dt_raw, '%y.%m.%d.').strftime('%Y%m%d')\n",
    "        except Exception:\n",
    "            write_dt = ''\n",
    "        \n",
    "        # 4-2. 상품명 수집\n",
    "        try:\n",
    "            item_nm_divs = reviews[review].findAll('div', {'class': '_2FXNMst_ak'})\n",
    "            if item_nm_divs:\n",
    "                item_nm_info_raw = item_nm_divs[0].get_text()\n",
    "\n",
    "                # dl 태그 안의 텍스트 추출 (없을 수도 있음)\n",
    "                dl_tag = item_nm_divs[0].find('dl', {'class': 'XbGQRlzveO'})\n",
    "                item_nm_info_for_del = dl_tag.get_text() if dl_tag else ''\n",
    "\n",
    "                # 텍스트 정제\n",
    "                item_nm_info = re.sub(item_nm_info_for_del, '', item_nm_info_raw)\n",
    "\n",
    "                # '제품 선택: ' 위치 찾기\n",
    "                str_start_idx = item_nm_info.find('제품 선택: ')\n",
    "                if str_start_idx != -1:\n",
    "                    item_nm = item_nm_info[str_start_idx + len('제품 선택: '):].strip()\n",
    "                else:\n",
    "                    item_nm = item_nm_info.strip()\n",
    "            else:\n",
    "                item_nm = ''\n",
    "        except Exception:\n",
    "            item_nm = ''\n",
    "        \n",
    "        # 4-3. 리뷰내용 수집\n",
    "        try:\n",
    "            review_div = reviews[review].findAll('div', {'class': '_1kMfD5ErZ6'})\n",
    "            if review_div:\n",
    "                span_tag = review_div[0].find('span', {'class': '_2L3vDiadT9'})\n",
    "                if span_tag:\n",
    "                    review_content_raw = span_tag.get_text()\n",
    "                    review_content = re.sub(' +', ' ', re.sub('\\n', ' ', review_content_raw))\n",
    "                else:\n",
    "                    review_content = ''\n",
    "            else:\n",
    "                review_content = ''\n",
    "        except Exception:\n",
    "            review_content = ''\n",
    "        \n",
    "        # 4-4. 수집데이터 저장\n",
    "        write_dt_lst.append(write_dt)\n",
    "        item_nm_lst.append(item_nm)\n",
    "        content_lst.append(review_content)\n",
    "\n",
    "    # 5. 리뷰 수집일자 기준 데이터 확인 (최근 1년치만 수집)\n",
    "    if write_dt_lst and write_dt_lst[-1] < date_cut:\n",
    "        break\n",
    "\n",
    "    # 6. 페이지 이동\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, f'#REVIEW > div > div._2LvIMaBiIO > div._2g7PKvqCKe > div > div > a:nth-child({page_ctl})').click()\n",
    "        time.sleep(5)\n",
    "    except Exception as e:\n",
    "        print(f\"페이지 이동 실패: {e}\")\n",
    "        break\n",
    "\n",
    "    page_num += 1\n",
    "    page_ctl += 1\n",
    "    if page_num % 10 == 1:\n",
    "        page_ctl = 3\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "0c522deb-c81d-48d1-975c-8d134da7e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\n",
    "              'Item_info' : item_nm_lst,\n",
    "              'Content' : content_lst,\n",
    "              'Date' : write_dt_lst })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "6fe42e5e-e549-47a1-9a58-293cc6981493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     20250721\n",
      "1     20250719\n",
      "2     20250719\n",
      "3     20250719\n",
      "4     20250713\n",
      "        ...   \n",
      "75    20240524\n",
      "76    20240516\n",
      "77    20240515\n",
      "78    20240514\n",
      "79    20240510\n",
      "Name: Date, Length: 80, dtype: object\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(result_df[\"Date\"])\n",
    "print(len(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "a368d961-9a90-4436-bf8a-4f591918c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('C:/Users/ksp45/Desktop/Zinc_Ivy.csv', index = None, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3085fbe2-3c30-41bb-9fdf-308762d7f8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
