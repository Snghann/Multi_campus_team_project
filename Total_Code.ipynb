{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["OKomvnszBTcx","uKjnDAWNCBbz","MQ0IFa7yCJKU","KDDsAU1_CM6z","B5eCU0e0CqJH","elNMd4IaC22Z","I68KQqALC7mR","A9sR-fkCCw7x","FDDAIpaQDRW6","jLDMWuNxDVj3"],"authorship_tag":"ABX9TyMnapPOaX4g8a721uFOnKTj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 크롤링"],"metadata":{"id":"OKomvnszBTcx"}},{"cell_type":"markdown","source":["### 아마존 리뷰 데이터 수집"],"metadata":{"id":"FYulECmuBU-B"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztTkxWqzBIrt"},"outputs":[],"source":["import math\n","import traceback\n","import time\n","import csv\n","import re\n","from selenium import webdriver\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.chrome.service import Service\n","from selenium.webdriver.chrome.options import Options\n","from selenium.webdriver.common.keys import Keys\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from webdriver_manager.chrome import ChromeDriverManager\n","import urllib.parse\n","import json\n","\n","# === 크롬 옵션 설정 ===\n","options = Options()\n","options.add_argument(\"--disable-blink-features=AutomationControlled\")\n","options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n","options.add_experimental_option(\"useAutomationExtension\", False)\n","options.add_argument(\"start-maximized\")\n","options.add_argument(\"disable-infobars\")\n","options.add_argument(\"disable-popup-blocking\")\n","options.add_argument(\n","    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",")\n","\n","service = Service(ChromeDriverManager().install())\n","driver = webdriver.Chrome(service=service, options=options)\n","\n","# === 사용자가 직접 입력할 ASIN 리스트 ===\n","# 여기에 크롤링하고 싶은 30개 (또는 원하는 개수) 제품의 ASIN을 입력하세요.\n","ASINS_TO_CRAWL = [\n","    \"B07MJL8NXR\",\n","    \"B08SRSRN7G\", \"B08FY6SCR8\", \"B0CK9QNYZW\", \"B07MFYYZ5B\", \"B0DRPSBQH3\",\n","    \"B07ZP4HBXS\", \"B07W6B8ZLZ\", \"B09VX8WLQQ\", \"B07ZP461TY\", \"B07MCCVZYC\",\n","    \"B0DDYDGCSD\" , \"B0015068TG\", \"B0DY1ZS88N\", \"B0F6F8TBR7\", \"B0DY21L16Y\",\n","    \"B0F3DNXDRZ\", \"B0791ZPVTY\", \"B0F3DRGDGM\", \"B09SGVCNFK\", \"B0791Y2LMB\",\n","    \"B09SGQVPDW\", \"B07NLQ5V6L\", \"B08WHYHPL5\", \"B08WHMBTM6\", \"B0DBRP7NN1\",\n","    \"B09NZ54BR4\", \"B0DBRP2KTM\", \"B0BV9749Q3\", \"B09NZPZ8Y6\", \"B0CPFX647Y\",\n","    \"B0CPFTBWYJ\", \"B005V9UG18\", \"B00AY6S2KU\", \"B003FDC2I2\", \"B0F3PZSNLQ\",\n","    \"B089ZVRR82\", \"B01KITQCW2\", \"B0DN83F6QS\", \"B09V4P2DVF\", \"B01KITQG0A\",\n","    \"B01KITQEPM\", \"B07ZZCM9SZ\", \"B0D6DKR58D\", \"B09G71BM3N\", \"B0854W9ND4\",\n","    \"B07ZZCDZST\", \"B0D7TFG59T\", \"B0B69YRPXH\", \"B08B2XCK56\", \"B0B75R8Z7X\",\n","    \"B01HOPJ2WU\", \"B07BL5ZHF9\", \"B07BL5BT2V\", \"B07BL5G7TC\", \"B0B6WRW3GX\",\n","    \"B01HOPJ8V0\", \"B01HOPJ3OC\", \"B0DS6MT455\", \"B0DS6LWMKJ\", \"B0DS6LGSV6\",\n","    \"B0D8MBS6XX\", \"B0D8M7RSHX\", \"B0D8M7K536\", \"B0DTMHYMG8\", \"B09V1S9168\",\n","    \"B0D823BK53\", \"B09V1S3V12\", \"B0DS6KMXHH\", \"B0DS6KYV4T\", \"B0DS6LSXXP\",\n","    \"B074P98SV7\", \"B07NH274NS\", \"B0C6YLVTHP\", \"B074P9D8JK\", \"B0DLCNXJD1\",\n","    \"B0DLBVHTB5\", \"B0DLCDBY96\", \"B0DHWD5WBM\", \"B0DHWDLW5X\", \"B0036F576I\",\n","    \"B0DQYV1Y51\", \"B06XWZHPN8\", \"B00166BBXW\", \"B0BSXXCD97\", \"B0034L4YGI\",\n","    \"B084WB9T61\", \"B0CFGBC9G2\", \"B01769TWGA\", \"B0036FBZPK\", \"B0CCWXBD5D\",\n","    \"B07BDS1YFX\", \"B085LSZCJ7\", \"B085LVFFKM\", \"B08B2J4DKZ\", \"B08TJ4LQ1N\",\n","    \"B08B7B3CF8\", \"B09LZZL1FF\", \"B0CTJ7G7N3\", \"B08GLMGVJQ\", \"B09B7Z7WGG\",\n","    \"B09PFK7H3W\", \"B09BC7V1JJ\", \"B08GLMT52Z\", \"B0BCSZPGQ3\", \"B079WNBTSH\",\n","    \"B0CM43QLM7\", \"B0B5M6RMFD\", \"B09BBWYD8X\", \"B0015068PA\", \"B0C5YVDRVM\",\n","    \"B09BBY5GPD\", \"B00BKL4KKY\", \"B0CDHNX333\", \"B00HKF9KFE\", \"B00BYOW7VG\",\n","    \"B0BKH8LN24\", \"B0BKH6MYD1\", \"B0CP8HZW65\", \"B0BKH4JXTM\", \"B01DDIRDZA\",\n","    \"B09GJVN2YZ\", \"B0DZY51RWP\", \"B0DZ8KV821\", \"B08QQKRWPR\", \"B08QQZ71P6\",\n","    \"B0BNFB7PSG\", \"B09NCJYC6K\", \"B09NCGMWX6\", \"B08YB4JQN4\", \"B08QQBGL95\",\n","    \"B08YS3TWTT\"\n","]\n","\n","# 모든 제품의 기본 리뷰 URL에 formatType=current_format 고정\n","# 리뷰 파일명에 사용될 Flavor 식별자.\n","FLAVOR_IDENTIFIER_FOR_FILENAME = \"current_format_reviews\"\n","\n","\n","def crawl_product_info_and_reviews_combined(asin, review_star_filters=None):\n","    if review_star_filters is None:\n","        review_star_filters = [\"5\", \"4\", \"3\", \"2\", \"1\"]  # 별점 필터 순서\n","\n","    star_filter_map = {\n","        \"5\": \"five_star\",\n","        \"4\": \"four_star\",\n","        \"3\": \"three_star\",\n","        \"2\": \"two_star\",\n","        \"1\": \"one_star\",\n","    }\n","\n","    product_data = {}\n","    product_url = f\"https://www.amazon.com/dp/{asin}\"\n","\n","    print(f\"\\n--- ASIN: {asin} 제품 정보 및 리뷰 수집 시작 ---\")\n","\n","    driver.get(product_url)\n","    time.sleep(3)\n","\n","    try:\n","        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, \"productTitle\")))\n","    except Exception as e:\n","        print(f\"오류: 제품 {asin} 상세페이지 로딩 실패 또는 productTitle 요소를 찾을 수 없습니다: {e}\")\n","        return None\n","\n","    if \"/pharmacy/\" in driver.current_url:\n","        print(f\"DEBUG: 제품 {asin} pharmacy 리디렉션 감지, 이 제품은 수집하지 않습니다.\")\n","        return None\n","\n","    # 제품명\n","    try:\n","        product_title = driver.find_element(By.ID, \"productTitle\").text.strip()\n","    except:\n","        product_title = \"N/A\"\n","        print(f\"DEBUG: ASIN {asin} 제품명 추출 실패\")\n","\n","    # 대표 이미지 URL\n","    try:\n","        img_url = driver.find_element(By.ID, \"landingImage\").get_attribute(\"src\")\n","    except:\n","        img_url = \"N/A\"\n","        print(f\"DEBUG: ASIN {asin} 이미지 URL 추출 실패\")\n","\n","    # 가격\n","    try:\n","        price_whole = driver.find_element(By.CSS_SELECTOR, \"span.a-price-whole\").text.strip()\n","        price_fraction = driver.find_element(By.CSS_SELECTOR, \"span.a-price-fraction\").text.strip()\n","        price_whole_clean = price_whole.replace(\",\", \"\")\n","        price = f\"${price_whole_clean}.{price_fraction}\"\n","        try:\n","            price_per_count = driver.find_element(By.CSS_SELECTOR, \"span.a-price a-price-symbol + span\").text.strip()\n","            price += f\" ({price_per_count})\"\n","        except:\n","            pass\n","    except:\n","        price = \"N/A\"\n","        print(f\"DEBUG: ASIN {asin} 가격 추출 실패\")\n","\n","    # Product Overview\n","    product_overview = {}\n","    try:\n","        overview_table = driver.find_element(By.ID, \"productOverview_feature_div\")\n","        rows = overview_table.find_elements(By.CSS_SELECTOR, \"tr\")\n","        for row in rows:\n","            try:\n","                th = row.find_element(By.TAG_NAME, \"th\").text.strip()\n","                td = row.find_element(By.TAG_NAME, \"td\").text.strip()\n","                product_overview[th] = td\n","            except:\n","                continue\n","    except:\n","        print(f\"DEBUG: ASIN {asin} Product Overview 추출 실패\")\n","\n","    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n","    time.sleep(4)\n","\n","    # Product Description\n","    product_description = \"\"\n","    try:\n","        desc_div = driver.find_element(By.ID, \"productDescription\")\n","        product_description = desc_div.text.strip()\n","    except:\n","        pass\n","    if not product_description:\n","        try:\n","            alt_desc = driver.find_element(By.CSS_SELECTOR, \"div#feature-bullets ~ div.a-section.a-spacing-small.a-spacing-top-small\")\n","            product_description = alt_desc.text.strip()\n","        except:\n","            print(f\"DEBUG: ASIN {asin} Product Description 추출 실패\")\n","            pass\n","\n","    # About this item\n","    about_items = []\n","    try:\n","        about_div = driver.find_element(By.ID, \"feature-bullets\")\n","        bullet_points = about_div.find_elements(By.CSS_SELECTOR, \"span.a-list-item\")\n","        for bp in bullet_points:\n","            txt = bp.text.strip()\n","            if txt:\n","                about_items.append(txt)\n","    except:\n","        try:\n","            about_div = driver.find_element(By.ID, \"feature-bullets_feature_div\")\n","            bullet_points = about_div.find_elements(By.CSS_SELECTOR, \"ul li\")\n","            for bp in bullet_points:\n","                txt = bp.text.strip()\n","                if txt:\n","                    about_items.append(txt)\n","        except:\n","            print(f\"DEBUG: ASIN {asin} About this item 추출 실패\")\n","            pass\n","\n","    # Important Information\n","    important_info = {}\n","    try:\n","        important_div = None\n","        try:\n","            important_div = driver.find_element(By.ID, \"important-information\")\n","        except:\n","            important_div = driver.find_element(By.ID, \"importantInformation_feature_div\")\n","\n","        if important_div:\n","            sections = important_div.find_elements(By.CSS_SELECTOR, \"div.a-section\")\n","            for section in sections:\n","                try:\n","                    heading = section.find_element(By.TAG_NAME, \"h3\").text.strip()\n","                    content = section.find_element(By.TAG_NAME, \"p\").text.strip()\n","                    important_info[heading] = content\n","                except:\n","                    text = section.text.strip()\n","                    if text:\n","                        important_info[f\"section_{len(important_info)+1}\"] = text\n","    except:\n","        print(f\"DEBUG: ASIN {asin} Important Information 추출 실패\")\n","        pass\n","\n","    # 제품 정보 딕셔너리 구성\n","    product_data = {\n","        \"asin\": asin,\n","        \"title\": product_title,\n","        \"image_url\": img_url,\n","        \"price\": price,\n","        \"product_overview\": json.dumps(product_overview, ensure_ascii=False), # JSON 문자열로 저장\n","        \"product_description\": product_description,\n","        \"about_this_item\": json.dumps(about_items, ensure_ascii=False),     # JSON 문자열로 저장\n","        \"important_information\": json.dumps(important_info, ensure_ascii=False), # JSON 문자열로 저장\n","        \"product_url\": product_url,\n","    }\n","\n","    print(f\"✅ ASIN {asin} 제품 정보 수집 완료.\")\n","\n","    # 리뷰 크롤링 시작\n","    all_reviews_raw = [] # 모든 별점의 리뷰 데이터 ( Flavor, Reviewer, Rating, Title, Body )\n","\n","    # 모든 제품의 기본 리뷰 URL에 formatType=current_format 고정\n","    base_review_url = f\"https://www.amazon.com/product-reviews/{asin}/ref=cm_cr_arp_d_viewopt_fmt?ie=UTF8&reviewerType=all_reviews&formatType=current_format\"\n","\n","\n","    for star_filter in review_star_filters:\n","        reviews_this_star = []\n","\n","        filter_param = star_filter_map.get(star_filter, None)\n","        if not filter_param:\n","            continue\n","\n","        review_url_with_stars = f\"{base_review_url}&filterByStar={filter_param}\"\n","\n","        driver.get(review_url_with_stars)\n","        time.sleep(3)\n","\n","        try:\n","            WebDriverWait(driver, 10).until(\n","                EC.presence_of_element_located((By.CSS_SELECTOR, \"span[data-hook='review-body']\"))\n","            )\n","        except Exception as e:\n","            print(f\"❌ {star_filter}⭐ 리뷰 초기 로드 실패 for ASIN {asin} (오류: {e})\")\n","            continue\n","\n","        while True:\n","            try:\n","                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n","                time.sleep(3)\n","\n","                review_blocks = driver.find_elements(By.CSS_SELECTOR, \"li[data-hook='review']\")\n","\n","                for review_block in review_blocks:\n","                    try:\n","                        rating_text = review_block.find_element(By.CSS_SELECTOR, \"i[data-hook='review-star-rating'] span.a-icon-alt\").text.strip()\n","                    except:\n","                        rating_text = \"N/A\"\n","\n","                    title = \"N/A\"\n","                    translated_title_text = \"\"\n","                    original_title_text = \"\"\n","\n","                    try:\n","                        translated_title_elem = review_block.find_element(By.CSS_SELECTOR, \"a[data-hook='review-title'] .cr-translated-review-content\")\n","                        translated_title_text = translated_title_elem.get_attribute('textContent').strip() if translated_title_elem else \"\"\n","                    except:\n","                        pass\n","\n","                    try:\n","                        original_title_elem = review_block.find_element(By.CSS_SELECTOR, \"a[data-hook='review-title']\")\n","                        original_title_text = original_title_elem.text.strip()\n","                    except:\n","                        pass\n","\n","                    if translated_title_text:\n","                        title = translated_title_text\n","                    elif original_title_text:\n","                        title = original_title_text\n","\n","\n","                    try:\n","                        reviewer = review_block.find_element(By.CSS_SELECTOR, \"span.a-profile-name\").text.strip()\n","                    except:\n","                        reviewer = \"N/A\"\n","\n","                    body = \"N/A\"\n","                    translated_body_text = \"\"\n","                    original_body_text = \"\"\n","                    try:\n","                        translated_body_elem = review_block.find_element(By.CSS_SELECTOR, \"span.cr-translated-review-content\")\n","                        translated_body_text = translated_body_elem.get_attribute('textContent').strip() if translated_body_elem else \"\"\n","                    except:\n","                        pass\n","\n","                    try:\n","                        original_body_elem = review_block.find_element(By.CSS_SELECTOR, \"span[data-hook='review-body']\")\n","                        original_body_text = original_body_elem.text.strip()\n","                    except:\n","                        pass\n","\n","                    if translated_body_text:\n","                        body = translated_body_text\n","                    elif original_body_text:\n","                        body = original_body_text\n","\n","\n","                    try:\n","                        format_strip = review_block.find_element(By.CSS_SELECTOR, \"a[data-hook='format-strip']\").text\n","                        flavor = \"N/A\"\n","                        for segment in format_strip.split(\"|\"):\n","                            if \"Flavor Name\" in segment:\n","                                flavor = segment.strip().replace(\"Flavor Name:\", \"\").strip()\n","                                break\n","                    except:\n","                        flavor = \"N/A\"\n","\n","                    review_data_row = {\n","                        \"Flavor\": flavor,\n","                        \"Reviewer\": reviewer,\n","                        \"Rating\": rating_text,\n","                        \"Title\": title,\n","                        \"Body\": body\n","                    }\n","                    if review_data_row not in reviews_this_star:\n","                        reviews_this_star.append(review_data_row)\n","\n","                try:\n","                    next_btn = driver.find_element(By.CSS_SELECTOR, \"li.a-last a\")\n","                    next_btn.click()\n","                    time.sleep(3)\n","                except:\n","                    break\n","\n","            except Exception as e:\n","                print(f\"오류: 리뷰 페이지 처리 중 오류 발생 (ASIN: {asin}, 별점: {star_filter}⭐): {e}\")\n","                traceback.print_exc()\n","                break\n","\n","        print(f\"✅ ASIN {asin}의 'Current Format'에 대한 {star_filter}⭐ 리뷰 {len(reviews_this_star)}개 수집됨\")\n","        all_reviews_raw += reviews_this_star\n","\n","    print(f\"✅ ASIN {asin}의 총 {len(all_reviews_raw)}건의 리뷰 수집 완료.\")\n","\n","    # --- 제품 정보와 리뷰를 하나의 CSV 파일로 저장 ---\n","    combined_filename = f\"amazon_product_and_reviews_combined_{asin}_{FLAVOR_IDENTIFIER_FOR_FILENAME}.csv\"\n","\n","    # CSV 헤더 정의\n","    # 제품 정보 필드 (리뷰와 겹치지 않게 'Product_' 접두사 사용)\n","    product_fields = [f\"Product_{k}\" for k in product_data.keys() if k not in [\"asin\"]]\n","    # 리뷰 필드 (기존 이름 사용)\n","    review_fields = [\"Flavor\", \"Reviewer\", \"Rating\", \"Title\", \"Body\"]\n","\n","    # ASIN은 모든 행에 공통으로 들어갈 것이므로 따로 정의\n","    fieldnames = [\"ASIN\"] + product_fields + review_fields\n","\n","    with open(combined_filename, \"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n","        writer = csv.DictWriter(f, fieldnames=fieldnames)\n","        writer.writeheader()\n","\n","        # 첫 번째 행에 제품 정보와 첫 번째 리뷰를 함께 저장 (리뷰가 있다면)\n","        # 리뷰가 없으면 제품 정보만 저장\n","        first_row_data = {\"ASIN\": asin}\n","\n","        # 제품 정보 추가\n","        for k, v in product_data.items():\n","            if k != \"asin\": # ASIN은 이미 위에서 추가했으므로 제외\n","                first_row_data[f\"Product_{k}\"] = v\n","\n","        if all_reviews_raw:\n","            # 첫 번째 리뷰 데이터 추가\n","            first_review = all_reviews_raw[0]\n","            for k, v in first_review.items():\n","                first_row_data[k] = v\n","            writer.writerow(first_row_data)\n","\n","            # 나머지 리뷰 데이터 추가 (제품 정보는 비워두고 리뷰 데이터만 채움)\n","            for review_row in all_reviews_raw[1:]:\n","                row_to_write = {\"ASIN\": asin} # ASIN은 계속 포함\n","                for k, v in review_row.items():\n","                    row_to_write[k] = v\n","                writer.writerow(row_to_write)\n","        else:\n","            # 리뷰가 없는 경우 제품 정보만 첫 행에 저장\n","            writer.writerow(first_row_data)\n","\n","    print(f\"✅ 제품 {asin} 정보 및 리뷰 총 {len(all_reviews_raw) + (1 if product_data else 0)}건 통합 저장 완료: {combined_filename}\")\n","\n","    return product_data # 이 함수는 더 이상 제품 정보만 반환하지 않지만, 호출 구조 유지를 위해 product_data 반환.\n","\n","# === 메인 실행 로직 ===\n","driver.get(\"https://www.amazon.com/\")\n","input(\"Amazon 웹페이지에서 로그인 완료 후, 콘솔에 Enter 키를 눌러주세요...\")\n","\n","print(f\"\\n--- {len(ASINS_TO_CRAWL)}개의 ASIN에 대한 제품 정보 및 리뷰 크롤링 시작 ---\")\n","\n","MAX_RETRIES = 3\n","\n","for i, asin in enumerate(ASINS_TO_CRAWL):\n","    print(f\"\\n[{i+1}/{len(ASINS_TO_CRAWL)}] ASIN: {asin} 크롤링 중...\")\n","\n","    retries = 0\n","    while retries < MAX_RETRIES:\n","        try:\n","            # 함수 이름 변경: crawl_product_info_and_reviews_combined\n","            result = crawl_product_info_and_reviews_combined(asin)\n","            if result:\n","                print(f\"✅ ASIN {asin} 크롤링 성공.\")\n","                break\n","            else:\n","                print(f\"⚠️ ASIN {asin} 제품 정보를 가져오지 못했습니다. 재시도합니다. (시도 {retries+1}/{MAX_RETRIES})\")\n","                retries += 1\n","                time.sleep(5)\n","        except Exception as e:\n","            print(f\"❌ ASIN {asin} 크롤링 중 예외 발생: {e}\")\n","            traceback.print_exc()\n","            retries += 1\n","            if retries < MAX_RETRIES:\n","                print(f\"재시도 중... (시도 {retries}/{MAX_RETRIES})\")\n","                time.sleep(10)\n","            else:\n","                print(f\"❌ ASIN {asin} 크롤링 {MAX_RETRIES}회 재시도 실패. 이 ASIN은 건너킵니다.\")\n","\n","    if retries == MAX_RETRIES and not result:\n","        print(f\"⚠️ ASIN {asin} 크롤링 최종 실패. 건너킵니다.\")\n","\n","print(\"\\n--- 모든 제품 정보 및 리뷰 크롤링이 완료되었습니다. ---\")\n","\n","driver.quit()"]},{"cell_type":"markdown","source":["### 네이버 리뷰 데이터 수집"],"metadata":{"id":"GTdTNPmxBm4e"}},{"cell_type":"code","source":["options = webdriver.ChromeOptions()  # 크롬 옵션 객체 생성\n","options.add_argument(\"window-size-1920x1080\")  # 전체화면\n","options.add_argument(\"disable-gpu\")\n","options.add_argument(\"disable-infobars\")\n","options.add_argument(\"--disable-extensions\")\n","options.add_argument(\"--no-sandbox\")"],"metadata":{"id":"UW_G4MTgBo4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chrome_driver_path = \"driver_path\"\n","service = Service(executable_path = chrome_driver_path)"],"metadata":{"id":"RJS-7XqBBwZg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["driver = webdriver.Chrome(service = service, options = options)\n","driver.implicitly_wait(3)"],"metadata":{"id":"xaiF1zCoBxwO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["driver.get(\"URL_PATH\")\n","time.sleep(3)"],"metadata":{"id":"lZ13ZJCJByo8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n","time.sleep(5)"],"metadata":{"id":"aPusV7-kBzwx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["driver.find_element(By.CSS_SELECTOR, \"#content > div > div._3CTsMZymJs > div:nth-child(3) > div._27jmWaPaKy > ul > li:nth-child(2) > a\").click()\n","time.sleep(5)"],"metadata":{"id":"N-OZ0OZ_B0tl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["driver.find_element(By.CSS_SELECTOR, \"#REVIEW > div > div._2LvIMaBiIO > div._3aC7jlfVdk > div._1txuie7UTH > ul > li:nth-child(2) > a\").click()\n","time.sleep(3)"],"metadata":{"id":"ZVGs96-7B1nJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 현재 페이지\n","page_num = 1\n","page_ctl = 3\n","\n","write_dt_lst = []\n","item_nm_lst = []\n","content_lst = []\n","\n","# 날짜\n","date_cut = (datetime.now() - timedelta(days=365)).strftime('%Y%m%d')\n","\n","while True:\n","    if page_num == 26:\n","        print(\"500개 수집 완료\")\n","        break\n","\n","    print(f'start : {page_num} page 수집 중, page_ctl:{page_ctl}')\n","\n","    # 1. 셀레니움으로 html 가져오기\n","    html_source = driver.page_source\n","\n","    # 2. bs4로 html 파싱\n","    soup = BeautifulSoup(html_source, 'html.parser')\n","    time.sleep(0.5)\n","\n","    # 3. 리뷰 정보 가져오기\n","    reviews = soup.findAll('li', {'class': 'BnwL_cs1av'})\n","\n","    # 4. 한 페이지 내에서 수집 가능한 리뷰 리스트에 저장\n","    for review in range(len(reviews)):\n","        try:\n","            # 4-1. 리뷰 작성일자 수집\n","            write_dt_raw = reviews[review].findAll('span', {'class': '_2L3vDiadT9'})[0].get_text()\n","            write_dt = datetime.strptime(write_dt_raw, '%y.%m.%d.').strftime('%Y%m%d')\n","        except Exception:\n","            write_dt = ''\n","\n","        # 4-2. 상품명 수집\n","        try:\n","            item_nm_divs = reviews[review].findAll('div', {'class': '_2FXNMst_ak'})\n","            if item_nm_divs:\n","                item_nm_info_raw = item_nm_divs[0].get_text()\n","\n","                # dl 태그 안의 텍스트 추출 (없을 수도 있음)\n","                dl_tag = item_nm_divs[0].find('dl', {'class': 'XbGQRlzveO'})\n","                item_nm_info_for_del = dl_tag.get_text() if dl_tag else ''\n","\n","                # 텍스트 정제\n","                item_nm_info = re.sub(item_nm_info_for_del, '', item_nm_info_raw)\n","\n","                # '제품 선택: ' 위치 찾기\n","                str_start_idx = item_nm_info.find('제품 선택: ')\n","                if str_start_idx != -1:\n","                    item_nm = item_nm_info[str_start_idx + len('제품 선택: '):].strip()\n","                else:\n","                    item_nm = item_nm_info.strip()\n","            else:\n","                item_nm = ''\n","        except Exception:\n","            item_nm = ''\n","\n","        # 4-3. 리뷰내용 수집\n","        try:\n","            review_div = reviews[review].findAll('div', {'class': '_1kMfD5ErZ6'})\n","            if review_div:\n","                span_tag = review_div[0].find('span', {'class': '_2L3vDiadT9'})\n","                if span_tag:\n","                    review_content_raw = span_tag.get_text()\n","                    review_content = re.sub(' +', ' ', re.sub('\\n', ' ', review_content_raw))\n","                else:\n","                    review_content = ''\n","            else:\n","                review_content = ''\n","        except Exception:\n","            review_content = ''\n","\n","        # 4-4. 수집데이터 저장\n","        write_dt_lst.append(write_dt)\n","        item_nm_lst.append(item_nm)\n","        content_lst.append(review_content)\n","\n","    # 5. 리뷰 수집일자 기준 데이터 확인 (최근 1년치만 수집)\n","    if write_dt_lst and write_dt_lst[-1] < date_cut:\n","        break\n","\n","    # 6. 페이지 이동\n","    try:\n","        driver.find_element(By.CSS_SELECTOR, f'#REVIEW > div > div._2LvIMaBiIO > div._2g7PKvqCKe > div > div > a:nth-child({page_ctl})').click()\n","        time.sleep(5)\n","    except Exception as e:\n","        print(f\"페이지 이동 실패: {e}\")\n","        break\n","\n","    page_num += 1\n","    page_ctl += 1\n","    if page_num % 10 == 1:\n","        page_ctl = 3\n","\n","print('done')"],"metadata":{"id":"aJovwPOLB2kx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df = pd.DataFrame({\n","              'Item_info' : item_nm_lst,\n","              'Content' : content_lst,\n","              'Date' : write_dt_lst })"],"metadata":{"id":"Fe7ks84AB4Wd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 옥션 리뷰 데이터 수집"],"metadata":{"id":"oIub2dOGB5qH"}},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# 🔽 복사한 <ul class=\"list-item\"> 전체 HTML을 여기에 붙여넣기\n","html = \"\"\"\n","\n","\"\"\"\n","\n","# 🌿 파싱 시작\n","soup = BeautifulSoup(html, \"html.parser\")\n","review_items = soup.select(\"li.list-item\")\n","\n","data = []\n","\n","for item in review_items:\n","    review_text = item.select_one('.box__review-text .text')\n","    writer = item.select_one('.text__writer')\n","    date = item.select_one('.text__date')\n","    rating = item.select_one('.sprite__vip.image__star .for-a11y')\n","    rating_value = ''\n","\n","    if rating:\n","        text = rating.get_text(strip=True)\n","        # 예: '이용자 평점 4점' → 숫자만 추출\n","        import re\n","        match = re.search(r'(\\d(?:\\.\\d)?)점', text)\n","        if match:\n","            rating_value = match.group(1)\n","\n","    data.append({\n","        '제품명': '제품명',\n","        '상품번호':'',\n","        '리뷰': review_text.get_text(strip=True) if review_text else '',\n","        '작성자': writer.get_text(strip=True) if writer else '',\n","        '날짜': date.get_text(strip=True) if date else '',\n","        '별점': rating_value\n","    })\n","\n","\n","# 🧾 CSV로 저장\n","df = pd.DataFrame(data)\n","df.to_csv(\"제품명.csv\", index=False, encoding=\"utf-8-sig\")\n","print(f\"✅ 저장 완료: 11st_reviews_ul.csv (총 {len(data)}개의 리뷰가 모였습니다.)\")\n"],"metadata":{"id":"2aYrE4I7B7DR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 분석"],"metadata":{"id":"uKjnDAWNCBbz"}},{"cell_type":"markdown","source":["### 워드 클라우드"],"metadata":{"id":"MQ0IFa7yCJKU"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","from mecab import MeCab # 'mecab-python3' 라이브러리에서 직접 MeCab을 불러옵니다.\n","import re\n","import os\n","from collections import Counter # 단어 빈도수를 세기 위해 Counter를 추가했습니다.\n","\n","# matplotlib 한글 폰트 설정\n","# 폰트 경로가 정확한지 확인해 주세요.\n","plt.rc('font', family='NanumBarunGothic')\n","plt.rcParams['axes.unicode_minus'] = False\n","\n","# Mecab 초기화 (사전 경로를 자동으로 찾아줍니다.)\n","try:\n","    mecab = MeCab()\n","    print(\"MeCab이 성공적으로 초기화되었습니다.\")\n","except Exception as e:\n","    print(f\"MeCab 초기화 중 오류 발생: {e}\")\n","    # MeCab 초기화 실패 시 스크립트를 종료합니다.\n","    exit()\n","\n","# --- 2. 함수 정의 ---\n","# 텍스트에서 명사를 추출하고 불용어를 제거하는 함수\n","def get_nouns(text, stop_words):\n","    text = str(text) # 입력값을 문자열로 변환하여 에러 방지\n","    # 한글, 영어, 숫자만 남기고 특수문자 제거\n","    text = re.sub('[^가-힣a-zA-Z0-9\\s]', '', text)\n","\n","    # 명사만 추출\n","    nouns = mecab.nouns(text)\n","\n","    # 한 글자 명사 및 불용어 제거\n","    # `stop_words` 리스트를 외부에서 받아서 더 유연하게 관리합니다.\n","    filtered_nouns = [n for n in nouns if len(n) > 1 and n not in stop_words]\n","\n","    return filtered_nouns\n","\n","# --- 3. 메인 로직 실행 ---\n","def main():\n","    # CSV 파일 불러오기 (실제 파일 경로로 변경)\n","    file_path = '/content/drive/MyDrive/데이터 분석 및 시각화/1. 키워드 추출/protein_1.csv'\n","\n","    try:\n","        df = pd.read_csv(file_path)\n","        print(\"CSV 파일이 성공적으로 로드되었습니다.\")\n","    except FileNotFoundError:\n","        print(f\"오류: {file_path} 파일을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n","        return # 파일이 없으면 함수 종료\n","\n","    # 네가 추가했던 불용어 리스트를 따로 정의\n","    stop_words = ['정도', '때문', '부분', '생각', '제품', '것', '저', '다', '배송']\n","\n","    # '리뷰' 컬럼의 모든 리뷰 텍스트를 하나의 문자열로 합칩니다.\n","    # 결측치(NaN)는 제외하고 합쳐줍니다.\n","    all_reviews = ' '.join(df['리뷰'].dropna().astype(str))\n","\n","    # 텍스트 데이터가 비어 있는지 확인\n","    if not all_reviews.strip():\n","        print(\"오류: '리뷰' 컬럼에 유효한 텍스트 데이터가 없어 워드 클라우드를 생성할 수 없습니다.\")\n","        return\n","\n","    # 명사 추출\n","    nouns = get_nouns(all_reviews, stop_words)\n","\n","    # 추출된 명사 리스트가 비어 있는지 확인 (흰 바탕 문제 방지)\n","    if not nouns:\n","        print(\"오류: 명사 추출 결과가 비어 있습니다. 워드 클라우드를 생성할 수 없습니다.\")\n","        return\n","\n","    # 명사 리스트의 빈도수를 계산하여 딕셔너리 형태로 변환\n","    word_counts = Counter(nouns)\n","\n","    # 워드 클라우드 생성\n","    wordcloud = WordCloud(\n","        font_path='/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf',\n","        width=800,\n","        height=400,\n","        max_words=50,\n","        background_color='white'\n","    )\n","    # 빈도수 딕셔너리를 사용하여 워드 클라우드 생성\n","    wordcloud.generate_from_frequencies(word_counts)\n","\n","    # 시각화\n","    plt.figure(figsize=(10, 8))\n","    plt.imshow(wordcloud, interpolation='bilinear')\n","    plt.axis('off')\n","    plt.show()\n","\n","    # 이미지 저장\n","    # 저장할 경로와 파일명을 설정해 주세요.\n","    save_path = '/content/drive/MyDrive/데이터 분석 및 시각화/1. 키워드 추출/image/protein_image.png'\n","    # wordcloud 객체의 to_file() 함수를 사용하여 이미지를 저장합니다.\n","    wordcloud.to_file(save_path)\n","    print(f\"이미지가 성공적으로 저장되었습니다: {save_path}\")\n","\n","# 이 코드를 실행합니다.\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"DKqpD5SjCDQZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 감성 분석 및 문서 요약"],"metadata":{"id":"KDDsAU1_CM6z"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","def split_reviews_by_language(file_path, english_start_row, english_end_row):\n","    \"\"\"\n","    전체 리뷰 데이터를 받아 영어와 한글 리뷰로 분리하여 CSV 파일로 저장하는 함수.\n","\n","    Args:\n","        file_path (str): 전체 리뷰 데이터가 담긴 CSV 파일 경로.\n","        english_start_row (int): 영어 리뷰의 시작 행 번호 (1부터 시작).\n","        english_end_row (int): 영어 리뷰의 끝 행 번호 (1부터 시작).\n","    \"\"\"\n","    try:\n","        # 1. 전체 데이터를 불러옵니다.\n","        df = pd.read_csv(file_path)\n","        print(f\"✔️ 전체 데이터 로드 완료: {len(df)}개 행\")\n","\n","        # 2. 영어 리뷰를 슬라이싱합니다.\n","        # pandas는 0부터 시작하므로 행 번호에서 1을 빼서 인덱스에 맞춥니다.\n","        english_df = df.iloc[english_start_row - 1 : english_end_row]\n","        print(f\"✔️ 영어 리뷰 추출 완료: {len(english_df)}개 행\")\n","\n","        # 3. 한글 리뷰를 슬라이싱합니다. (영어 리뷰를 제외한 나머지)\n","        korean_df = df.drop(index=range(english_start_row - 1, english_end_row))\n","        print(f\"✔️ 한글 리뷰 추출 완료: {len(korean_df)}개 행\")\n","\n","        # 4. 각 DataFrame을 새로운 CSV 파일로 저장할 경로를 설정합니다.\n","        output_folder = '/content/drive/MyDrive/데이터 분석 및 시각화/1. 키워드 추출'\n","        if not os.path.exists(output_folder):\n","            os.makedirs(output_folder)\n","            print(f\"'{output_folder}' 폴더가 생성되었습니다.\")\n","\n","        # 5. 각 DataFrame을 새로운 CSV 파일로 저장합니다.\n","        english_file_path = os.path.join(output_folder, '영어_리뷰_데이터.csv')\n","        korean_file_path = os.path.join(output_folder, '한글_리뷰_데이터.csv')\n","\n","        english_df.to_csv(english_file_path, index=False)\n","        korean_df.to_csv(korean_file_path, index=False)\n","\n","        print(\"\\n🎉 모든 작업이 완료되었습니다!\")\n","        print(f\" '영어_리뷰_데이터.csv' 파일과 '한글_리뷰_데이터.csv' 파일이 '{output_folder}'에 저장되었습니다.\")\n","\n","    except FileNotFoundError:\n","        print(f\"오류: {file_path} 파일을 찾을 수 없습니다.\")\n","    except Exception as e:\n","        print(f\"오류가 발생했습니다: {e}\")\n","\n","# 실행 코드\n","file_path = '/content/drive/MyDrive/데이터 수집/3. 전처리X 데이터 통합/통합데이터(간단한_텍스트_전처리).csv'\n","english_start_row = 67849\n","english_end_row = 130700\n","\n","split_reviews_by_language(file_path, english_start_row, english_end_row)"],"metadata":{"id":"mNML1ukFCN5Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","# 1. 파일 경로를 지정해 주세요.\n","file_path = '/content/drive/MyDrive/데이터 분석 및 시각화/1. 키워드 추출/영어_리뷰_데이터.csv'\n","\n","try:\n","    df = pd.read_csv(file_path)\n","\n","    # 2. 총 행 개수와 중간점 계산\n","    total_rows = len(df)\n","    split_point = total_rows // 2\n","\n","    print(f\"✔️ 데이터의 총 행 개수: {total_rows}\")\n","    print(f\"✔️ 데이터를 나눌 중간점: {split_point}\")\n","\n","    # 3. 데이터프레임을 두 개로 분할\n","    df_part1 = df.iloc[:split_point].copy()\n","    df_part2 = df.iloc[split_point:].copy()\n","\n","    # 4. 원하는 경로와 파일 이름으로 각각 저장하기\n","    output_folder = '/content/drive/MyDrive/데이터 분석 및 시각화/1. 키워드 추출'\n","\n","    # 폴더가 없으면 새로 생성\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    # 첫 번째 파일 경로 설정 및 저장\n","    output_path1 = os.path.join(output_folder, '영어_리뷰_데이터_part1.csv')\n","    df_part1.to_csv(output_path1, index=False, encoding='utf-8-sig')\n","\n","    # 두 번째 파일 경로 설정 및 저장\n","    output_path2 = os.path.join(output_folder, '영어_리뷰_데이터_part2.csv')\n","    df_part2.to_csv(output_path2, index=False, encoding='utf-8-sig')\n","\n","    print(f\"\\n🎉 파일이 아래 두 경로에 성공적으로 저장되었습니다!\")\n","    print(f\"- 첫 번째 파일: '{output_path1}'\")\n","    print(f\"- 두 번째 파일: '{output_path2}'\")\n","\n","except FileNotFoundError:\n","    print(f\"오류: '{file_path}' 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")"],"metadata":{"id":"syyYU4fTCTvk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 한글 리뷰"],"metadata":{"id":"U7qeXJoCCXON"}},{"cell_type":"code","source":["\n","def chunk_text(reviews_list, max_tokens=500):\n","    \"\"\"리뷰 리스트를 받아 최대 토큰 수에 맞게 텍스트 덩어리로 나누는 함수\"\"\"\n","    text_to_chunk = \" \".join(reviews_list)\n","    chunks = []\n","    current_chunk = \"\"\n","    current_tokens = 0\n","    sentences = text_to_chunk.split('.')\n","    for sentence in sentences:\n","        sentence = sentence.strip()\n","        if not sentence: continue\n","        sentence_tokens = len(sentence.split())\n","        if current_tokens + sentence_tokens > max_tokens:\n","            chunks.append(current_chunk.strip())\n","            current_chunk = sentence + \". \"\n","            current_tokens = sentence_tokens\n","        else:\n","            current_chunk += sentence + \". \"\n","            current_tokens += sentence_tokens\n","    if current_chunk: chunks.append(current_chunk.strip())\n","    return chunks\n","\n","def summarize_korean(text, summarizer):\n","    \"\"\"한글 리뷰만 요약하는 함수\"\"\"\n","    try:\n","        return summarizer(text, max_length=150, min_length=30)[0]['summary_text']\n","    except Exception as e:\n","        return f\"요약 실패: {e}\"\n","\n","def main():\n","    print(\"--- Hugging Face 기반 한글 리뷰 카테고리별 분석 시작 ---\")\n","\n","    # 1. 한글 리뷰 데이터 파일을 불러옵니다. (경로를 확인해 주세요)\n","    file_path = '/content/drive/MyDrive/데이터 분석 및 시각화/1. 키워드 추출/한글_리뷰_데이터.csv'\n","    try:\n","        df = pd.read_csv(file_path)\n","    except FileNotFoundError:\n","        print(f\"오류: {file_path} 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n","        return\n","\n","    # 2. 분석할 카테고리 리스트를 정의합니다.\n","    categories = ['단백질', '비타민', '아연', '오메가3', '유산균', '단백질 쉐이크', '멀티비타민']\n","\n","    # 3. 감성 분석 모델을 로드합니다.\n","    print(\"\\n[1단계] 감성 분석 모델을 로드하고 있습니다...\")\n","    try:\n","        classifier = pipeline(\n","            \"sentiment-analysis\",\n","            model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n","            tokenizer=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n","            truncation=True,\n","            max_length=500\n","        )\n","    except Exception as e:\n","        print(f\"감성 분석 모델 로드 중 오류가 발생했습니다: {e}\")\n","        return\n","\n","    # 4. 한글 요약 모델을 로드합니다.\n","    print(\"[2단계] 한글 요약 모델을 로드하고 있습니다...\")\n","    try:\n","        korean_summarizer = pipeline(\n","            \"summarization\",\n","            model=\"lcw99/t5-base-korean-text-summary\"\n","        )\n","    except Exception as e:\n","        print(f\"한글 요약 모델 로드 중 오류가 발생했습니다: {e}\")\n","        return\n","\n","    # 요약 결과를 저장할 리스트를 초기화합니다.\n","    summary_results = []\n","\n","    # 5. 카테고리별 분석 루프 시작\n","    for category in categories:\n","        print(f\"\\n--- {category} 카테고리 분석 시작 ---\")\n","\n","        # 5-1. 해당 카테고리의 리뷰만 추출합니다.\n","        category_df = df[df['카테고리'] == category].copy()\n","\n","        if category_df.empty:\n","            print(\"해당 카테고리의 리뷰가 없습니다. 다음 카테고리로 넘어갑니다.\")\n","            continue\n","\n","        # 5-2. 감성 분석을 진행합니다.\n","        print(\"감성 분석 중...\")\n","        category_df['sentiment'] = category_df['리뷰'].apply(\n","            lambda review: classifier(review)[0]['label'] if isinstance(review, str) else 'neutral'\n","        )\n","        print(\"분석 완료.\")\n","\n","        # 5-3. 긍정/부정 리뷰를 분리합니다.\n","        positive_reviews = category_df[category_df['sentiment'] == 'positive']['리뷰'].tolist()\n","        negative_reviews = category_df[category_df['sentiment'] == 'negative']['리뷰'].tolist()\n","\n","        # 5-4. 긍정 리뷰 요약\n","        if positive_reviews:\n","            print(f\"✔️ 긍정 리뷰 ({len(positive_reviews)}개) 요약\")\n","            positive_chunks = chunk_text(positive_reviews)\n","            for i, chunk in enumerate(positive_chunks):\n","                summary = summarize_korean(chunk, korean_summarizer)\n","                # 요약 결과를 리스트에 추가합니다.\n","                summary_results.append({\n","                    'category': category,\n","                    'sentiment': 'positive',\n","                    'summary': summary\n","                })\n","\n","        # 5-5. 부정 리뷰 요약\n","        if negative_reviews:\n","            print(f\"✔️ 부정 리뷰 ({len(negative_reviews)}개) 요약\")\n","            negative_chunks = chunk_text(negative_reviews)\n","            for i, chunk in enumerate(negative_chunks):\n","                summary = summarize_korean(chunk, korean_summarizer)\n","                # 요약 결과를 리스트에 추가합니다.\n","                summary_results.append({\n","                    'category': category,\n","                    'sentiment': 'negative',\n","                    'summary': summary\n","                })\n","\n","    # 6. 요약 결과를 CSV 파일로 저장합니다.\n","    print(\"\\n--- 분석 결과를 CSV 파일로 저장합니다. ---\")\n","    output_folder = '/content/drive/MyDrive/데이터 분석 및 시각화/1. 키워드 추출/리뷰 결과'\n","    output_file = '한글_리뷰_요약_결과.csv'\n","    output_path = os.path.join(output_folder, output_file)\n","\n","    if summary_results:\n","        summary_df = pd.DataFrame(summary_results)\n","        summary_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n","        print(f\"🎉 요약 결과가 '{output_path}'에 성공적으로 저장되었습니다!\")\n","    else:\n","        print(\"저장할 요약 결과가 없습니다.\")\n","\n","\n","if __name__ == \"__main__\":\n","    # 필요한 라이브러리가 없다면 아래 코드를 실행해 설치하세요.\n","    # !pip install transformers pandas torch\n","    main()\n"],"metadata":{"id":"DQ9kegYJCW2i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 영어 리뷰"],"metadata":{"id":"Xh4ryrd8ClEo"}},{"cell_type":"code","source":["def chunk_text(reviews_list, max_tokens=300):\n","    \"\"\"리뷰 리스트를 받아 최대 토큰 수에 맞게 텍스트 덩어리로 나누는 함수\"\"\"\n","    text_to_chunk = \" \".join(reviews_list)\n","    chunks = []\n","    current_chunk = \"\"\n","    current_tokens = 0\n","    # 문장 분리를 위한 정규식\n","    sentences = re.split(r'(?<!\\.\\w)(?<![A-Z][a-z])(?<=\\.|\\?|\\!)\\s', text_to_chunk)\n","    for sentence in sentences:\n","        sentence = sentence.strip()\n","        if not sentence: continue\n","        sentence_tokens = len(sentence.split())\n","        if current_tokens + sentence_tokens > max_tokens:\n","            chunks.append(current_chunk.strip())\n","            current_chunk = sentence + \" \"\n","            current_tokens = sentence_tokens\n","        else:\n","            current_chunk += sentence + \" \"\n","            current_tokens += sentence_tokens\n","    if current_chunk: chunks.append(current_chunk.strip())\n","    return chunks\n","\n","def summarize_english(text, summarizer):\n","    \"\"\"영어 리뷰만 요약하는 함수\"\"\"\n","    try:\n","        # 모델의 최대 입력 길이를 고려해 텍스트를 자릅니다.\n","        max_model_length = 512\n","        if len(text.split()) > max_model_length:\n","            text = \" \".join(text.split()[:max_model_length])\n","\n","        return summarizer(text, max_length=150, min_length=30)[0]['summary_text']\n","    except Exception as e:\n","        return f\"요약 실패: {e}\"\n","\n","def main():\n","    print(\"--- Hugging Face 기반 고유번호 & 카테고리별 감성 분석 및 요약 ---\")\n","\n","    # 1. 영어 리뷰 데이터 파일을 불러옵니다. (경로를 확인해 주세요)\n","    file_path = '/content/drive/MyDrive/데이터 분석 및 시각화/1. 키워드 추출/영어_리뷰_데이터_part1.csv'\n","    try:\n","        df = pd.read_csv(file_path)\n","        # 필요한 열이 있는지 확인\n","        if '고유번호' not in df.columns or '리뷰' not in df.columns or '카테고리' not in df.columns:\n","            print(\"오류: 데이터프레임에 '고유번호', '카테고리' 또는 '리뷰' 열이 없습니다. 열 이름을 확인해 주세요.\")\n","            return\n","    except FileNotFoundError:\n","        print(f\"오류: {file_path} 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n","        return\n","\n","    # 리뷰 열의 빈 값을 모두 빈 문자열로 채워줍니다.\n","    df['리뷰'] = df['리뷰'].fillna('')\n","\n","    # 리뷰 열의 모든 값을 문자열 타입으로 변환합니다.\n","    df['리뷰'] = df['리뷰'].astype(str)\n","\n","    # 2. 감성 분석 모델을 로드합니다.\n","    print(\"\\n[1단계] 감성 분석 모델을 로드하고 있습니다...\")\n","    try:\n","        classifier = pipeline(\n","            \"sentiment-analysis\",\n","            model=\"AnkitAI/reviews-roberta-base-sentiment-analysis\",\n","            tokenizer=\"AnkitAI/reviews-roberta-base-sentiment-analysis\",\n","            truncation=True,\n","            max_length=512\n","        )\n","    except Exception as e:\n","        print(f\"감성 분석 모델 로드 중 오류가 발생했습니다: {e}\")\n","        return\n","\n","    # 3. 영어 요약 모델을 로드합니다.\n","    print(\"[2단계] 영어 요약 모델을 로드하고 있습니다...\")\n","    try:\n","        english_summarizer = pipeline(\n","            \"summarization\",\n","            model=\"mabrouk/amazon-review-summarizer-bart\"\n","        )\n","    except Exception as e:\n","        print(f\"영어 요약 모델 로드 중 오류가 발생했습니다: {e}\")\n","        return\n","\n","    # 4. 리뷰에 감성 분석 결과를 추가합니다.\n","    print(\"\\n[3단계] 리뷰 감성을 분석하고 있습니다...\")\n","    # 리뷰 데이터를 리스트로 변환\n","    reviews_list = df['리뷰'].tolist()\n","\n","    # 리스트 전체를 한 번에 모델에 전달\n","    results = classifier(reviews_list)\n","\n","    # 결과만 데이터프레임에 추가 (모델이 직접 중립을 분류하므로 로직 단순화)\n","    def get_sentiment(result):\n","        # 'AnkitAI' 모델은 결과 딕셔너리를 하나만 반환합니다.\n","        label = result['label']\n","\n","        # 모델 라벨(POSITIVE, NEGATIVE)을 그대로 사용\n","        return label\n","\n","    # 새로 정의한 함수를 사용하여 감성 열을 채웁니다.\n","    # 결과는 [{'label': 'POSITIVE', 'score': 0.99}, ...]와 같은 형태입니다.\n","    df['sentiment'] = [get_sentiment(result) for result in results]\n","    print(\"분석 완료.\")\n","\n","    # 5. 고유번호, 카테고리, 감성별로 그룹화하고 요약합니다.\n","    print(\"\\n[4단계] 고유번호, 카테고리, 감성별로 리뷰를 요약하고 있습니다...\")\n","\n","    # '고유번호', '카테고리', 'sentiment'를 기준으로 데이터를 그룹화합니다.\n","    grouped_df = df.groupby(['고유번호', '카테고리', 'sentiment'])['리뷰'].apply(lambda x: ' '.join(x)).reset_index()\n","\n","    # 요약 결과를 저장할 리스트를 초기화합니다.\n","    summary_results = []\n","\n","    for index, row in grouped_df.iterrows():\n","        unique_id = row['고유번호']\n","        category = row['카테고리']\n","        sentiment = row['sentiment']\n","        reviews_text = row['리뷰']\n","\n","        print(f\"--- 고유번호: {unique_id}, 카테고리: {category}, 감성: {sentiment} 요약 시작 ---\")\n","\n","        # 텍스트를 청크로 나누고 요약\n","        chunks = chunk_text([reviews_text])\n","        for chunk in chunks:\n","            summary = summarize_english(chunk, english_summarizer)\n","            summary_results.append({\n","                '고유번호': unique_id,\n","                '카테고리': category,\n","                'sentiment': sentiment,\n","                'summary': summary\n","            })\n","\n","    # 6. 요약 결과를 CSV 파일로 저장합니다.\n","    print(\"\\n--- 분석 결과를 CSV 파일로 저장합니다. ---\")\n","    output_folder = '/content/drive/MyDrive/데이터 분석 및 시각화/1. 키워드 추출/리뷰 결과'\n","    output_file = '영어리뷰_감성_요약_결과_part1.csv'\n","    output_path = os.path.join(output_folder, output_file)\n","\n","    if summary_results:\n","        summary_df = pd.DataFrame(summary_results)\n","        # 폴더가 없으면 생성\n","        os.makedirs(output_folder, exist_ok=True)\n","        summary_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n","        print(f\"🎉 요약 결과가 '{output_path}'에 성공적으로 저장되었습니다!\")\n","    else:\n","        print(\"저장할 요약 결과가 없습니다.\")\n","\n","\n","if __name__ == \"__main__\":\n","    # 필요한 라이브러리가 없다면 아래 코드를 실행해 설치하세요.\n","    # !pip install transformers pandas torch\n","    main()"],"metadata":{"id":"kHxmAEPTClw8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### GCP gemini API 이용한 리뷰요약"],"metadata":{"id":"B5eCU0e0CqJH"}},{"cell_type":"code","source":["# llm (genai)\n","!pip install llama-index-llms-google-genai llama-index\n","\n","# 임베딩 (genai)\n","!pip install llama-index-embeddings-google-genai\n","\n","!pip install --upgrade google-generativeai\n","\n","### 필요한 함수 임폴트\n","import os\n","from dotenv import load_dotenv\n","# from llama_index.llms.openai import OpenAI\n","from llama_index.llms.google_genai import GoogleGenAI\n","# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from llama_index.core import Settings, Document, VectorStoreIndex\n","from llama_index.core.tools import QueryEngineTool, ToolMetadata\n","from llama_index.core.agent import ReActAgent\n","import tqdm\n","import pandas as pd\n","\n","### df_grouped 데이터 프레임 임폴트\n","\n","import pandas as pd\n","\n","file_path = '/content/drive/MyDrive/임베딩/GCP gemini API 활용/1. 리뷰통합.csv'\n","\n","df_grouped = pd.read_csv(file_path)\n","\n","# df_grouped\n","\n","### 필요한 함수 임폴트\n","import os\n","import json\n","import pandas\n","import pickle\n","from dotenv import load_dotenv\n","import google.generativeai as generativeai\n","import pandas as pd\n","import random\n","import time\n","import re\n","\n","### .env file 로드\n","load_dotenv('/content/drive/MyDrive/임베딩/GCP gemini API 활용/.env')\n","\n","### gemini key 불러오기기\n","GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n","generativeai.configure(api_key=GOOGLE_API_KEY)\n","\n","## API 키 확인\n","\n","import google.generativeai as generativeai\n","print(os.getenv(\"GOOGLE_API_KEY\"))  # 올바른 값이 나오는지 확인\n","\n","### 감성 분석 및 근거가 되는 keyword 추출 함수 정의\n","def analyze_review(text_input):\n","    # prompt 생성\n","    prompt = f\"\"\"\n","    다음 텍스트는 건강기능식품에 관한 소비자 리뷰입니다. 제품 하나당 모든 리뷰가 '/'로 구분되어져 포함되어 있습니다.\n","    해당 리뷰의 내용에서 긍정인 내용, 부정인 내용, 그리고 중립인 내용을 분류를 하고, 각 감성별로 리뷰를 요약하여 JSON 형식으로 제시해 주세요.\n","    각 감성별 리뷰 요약은 맥락이 비슷한 것만 남기고 요약을 하여, 각 감성별 리뷰의 글자 수가 300자를 넘지 않도록 요약해 주세요.\n","    그리고 리뷰 요약할 때 없는 내용을 창조하면 안되고, 리뷰 내용에 100% 충실하게 요약해야 해야 합니다.\n","    JSON 형식만 출력하세요. 아래 형식 외의 설명 문구는 절대 쓰지 마세요.\n","\n","    텍스트: {text_input}\n","\n","    출력 형식 예시:\n","    {{\n","      \"정확도\": 85,\n","      \"감성별 리뷰 요약\": {{\n","        \"긍정\": [\"긍정 리뷰 요약\"],\n","        \"부정\": [\"부정 리뷰 요약\"],\n","        \"중립\": [\"중립 리뷰 요약\"]\n","      }}\n","    }}\n","    \"\"\"\n","\n","\n","    try:\n","        # 텍스트 분석 결과 생성\n","        model = generativeai.GenerativeModel(\"gemini-2.5-pro\")\n","\n","        # generation_config 객체를 생성하여 temperature를 설정합니다.\n","        # temperature 값은 0.0 (가장 보수적)에서 1.0 (가장 창의적) 사이로 조절할 수 있습니다.\n","        generation_config = generativeai.types.GenerationConfig(\n","            temperature=0.0,  # 원하는 temperature 값으로 변경하세요 (예: 0.2, 0.5, 0.9 등)\n","            top_p=0.9,\n","            top_k=50\n","        )\n","\n","        response = model.generate_content(\n","            contents=[prompt],\n","            generation_config=generation_config # 여기에 generation_config를 전달합니다.\n","        )\n","\n","\n","        result_str = response.text\n","        if result_str:\n","            print(f'결과 : {result_str}')\n","\n","            # JSON 부분만 추출\n","            match = re.search(r\"\\{[\\s\\S]*\\}\", result_str)\n","            if match:\n","                json_text = match.group(0).strip()\n","                try:\n","                    parsed_json = json.loads(json_text)\n","                    return parsed_json\n","                except json.JSONDecodeError:\n","                    print(\"JSON 디코딩 실패. 추출된 내용:\", json_text)\n","                    return None\n","            else:\n","                print(\"JSON 패턴을 찾지 못했습니다.\")\n","                return None\n","\n","\n","    except Exception as e:\n","        print(f'API 호출 오류 : {e}')\n","        return None\n","\n","\n","\n","from tqdm.notebook import tqdm  # Colab/Jupyter용 진행바\n","\n","### 전체 텍스트를 처리하는 함수 정의 (tqdm 적용)\n","def process_multiple_texts(text_list):\n","    results = {}\n","    for i, text_input in enumerate(tqdm(text_list, desc=\"리뷰 처리 진행률\")):\n","        retry_count = 0\n","        max_retries = 5  # 최대 재시도 횟수\n","        wait_time = 20  # 초기 대기 시간 (초)\n","\n","        while retry_count < max_retries:\n","            print(f\"텍스트 {i+1} 처리 시도 {retry_count + 1}...\")\n","            result = analyze_review(text_input)\n","            if result:\n","            #     results[f\"텍스트 {i+1}\"] = result\n","            #     break  # 성공 시 루프 종료\n","            # else:\n","            #     retry_count += 1\n","            #     wait_time = wait_time * 2 + random.uniform(0, 1)  # 지수 백오프 + 약간의 임의 시간 추가\n","            #     print(f\"API 요청 실패. {wait_time:.2f}초 후 재시도...\")\n","            #     time.sleep(wait_time)\n","\n","                result = analyze_review(text_input)\n","\n","                # 성공 조건을 \"올바른 딕셔너리(JSON 파싱 성공)\"로 한정\n","                if isinstance(result, dict):\n","                    results[f\"텍스트 {i+1}\"] = result\n","                    break  # 성공 시 루프 종료\n","                else:\n","                    retry_count += 1\n","                    wait_time = wait_time * 2 + random.uniform(0, 1)\n","                    print(f\"API 요청 또는 JSON 파싱 실패. {wait_time:.2f}초 후 재시도...\")\n","                    time.sleep(wait_time)\n","\n","        else:  # 최대 재시도 횟수 초과 시\n","            results[f\"텍스트 {i+1}\"] = \"감정 키워드 추출 실패 (최대 재시도 횟수 초과)\"\n","\n","    return results\n","\n","\n","\n","\n","# 여러 텍스트 처리\n","all_results = process_multiple_texts(review_text)\n","\n","# 최종 결과 출력\n","# print(all_results)\n","\n","# 최종 결과를 dict 자료 구조로 변환\n","with open('review_analysis.pkl', 'wb') as fw:\n","    pickle.dump(all_results, fw)\n","\n","# 저장된 결과를 다시 불러오기\n","with open('review_analysis.pkl', 'rb') as fr:\n","    loaded_data = pickle.load(fr)\n","\n","print(f'리뷰 데이터 분석의 결과 : \\n{loaded_data}')"],"metadata":{"id":"V6CHOL6VCtvu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 청킹 및 임베딩"],"metadata":{"id":"elNMd4IaC22Z"}},{"cell_type":"code","source":["# 필요한 라이브러리 설치\n","!pip install pandas sentence_transformers --upgrade llama-index tqdm nltk llama-index-llms-google-genai llama-index-embeddings-huggingface\n","\n","# 필요한 라이브러리 임폴트\n","import pandas as pd\n","from sentence_transformers import SentenceTransformer\n","from llama_index.core.node_parser import SentenceSplitter # from llama_index.core.node_parser.text.sentence import SentenceSplitter와 같음\n","from tqdm import tqdm\n","import ast\n","\n","# 데이터 프레임 불러오기\n","df = pd.read_csv('/content/drive/MyDrive/임베딩/GCP gemini API 활용/6.리뷰분석(감성_리뷰만 있는 버전)')\n","\n","# 1. CSV 불러오기 (리뷰 텍스트가 '리뷰' 컬럼에 있다고 가정)\n","df = pd.read_csv('/content/drive/MyDrive/임베딩/GCP gemini API 활용/6.리뷰분석(감성_리뷰만 있는 버전)')\n","\n","# 2. 문장 단위 청킹 함수 정의\n","def chunk_text(text, chunk_size=200, chunk_overlap=50):\n","    splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n","    chunks = splitter.split_text(text)\n","    return chunks\n","\n","# 3. 임베딩 모델 로드 (무료 다국어 모델)\n","model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n","\n","# 4. 결과 저장용 리스트 준비\n","rows = []\n","\n","# 5. 전체 리뷰에 대해 처리 (청킹 + 임베딩)\n","for idx, row in tqdm(df.iterrows(), total=len(df)):\n","    고유번호 = row['고유번호']\n","    제품명 = row['제품명']\n","    카테고리 = row['카테고리']\n","    상세정보 = row['상세정보']\n","    긍정리뷰 = row['긍정_리뷰']\n","    부정리뷰 = row['부정_리뷰']\n","    중립리뷰 = row['중립_리뷰']\n","\n","    # 결측치나 숫자 문제 해결: 빈 문자열로 채우고 문자열 변환\n","    if pd.isna(긍정리뷰):\n","        긍정리뷰 = ''\n","    긍정리뷰 = str(긍정리뷰)\n","\n","    if 긍정리뷰.strip() == '':\n","        continue  # 빈 텍스트면 처리하지 않음\n","\n","    chunks = chunk_text(긍정리뷰)\n","    for chunk in chunks:\n","        embedding = model.encode(chunk).tolist()\n","        rows.append({\n","            '고유번호': 고유번호,\n","            '제품명' : 제품명,\n","            '카테고리' : 카테고리,\n","            '상세정보' : 상세정보,\n","            '긍정리뷰' : 긍정리뷰,\n","            '부정리뷰' : 부정리뷰,\n","            '중립리뷰' : 중립리뷰,\n","            '긍정_청크': chunk,\n","            '긍정리뷰_임베딩': embedding\n","        })\n","\n","# 6. DataFrame으로 변환\n","result_df = pd.DataFrame(rows)\n","\n","# 7. 임베딩 벡터를 문자열로 저장하기 위해 변환\n","result_df['긍정리뷰_임베딩'] = result_df['긍정리뷰_임베딩'].apply(lambda x: str(x))\n","\n","# 8. CSV로 저장\n","result_df.to_csv('/content/drive/MyDrive/임베딩/GCP gemini API 활용/reviews_chunked_embeddings4.csv', index=False)\n","\n","print(\"처리 완료! '/content/drive/MyDrive/임베딩/GCP gemini API 활용/reviews_chunked_embeddings4.csv' 파일에 저장되었습니다.\")"],"metadata":{"id":"Ry48qSZLC46A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 코사인 유사도 계산"],"metadata":{"id":"I68KQqALC7mR"}},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","\n","file_path4 = '/content/drive/MyDrive/임베딩/GCP gemini API 활용/reviews_chunked_embeddings4.csv'\n","\n","df = pd.read_csv(file_path4)\n","\n","# 문자열 컬럼 -> 리스트 변환\n","df['긍정리뷰_임베딩_int'] = df['긍정리뷰_임베딩'].apply(ast.literal_eval)\n","\n","print(type(df.loc[0, '긍정리뷰_임베딩_int']))  # <class 'list'>\n","\n","condition_zinc = (df.loc[:,'카테고리']=='아연')\n","df_zinc = df.loc[condition_zinc,:]\n","\n","condition_vitamin = (df.loc[:,'카테고리']=='비타민')\n","df_vitamin = df.loc[condition_vitamin,:]\n","\n","condition_probiotics = (df.loc[:,'카테고리']=='유산균')\n","df_probiotics = df.loc[condition_probiotics,:]\n","\n","condition_omega3 = (df.loc[:,'카테고리']=='오메가3')\n","df_omega3 = df.loc[condition_omega3,:]\n","\n","condition_protein = (df.loc[:,'카테고리']=='단백질')\n","df_protein = df.loc[condition_protein,:]\n","\n","### 코사인 유사도 계산\n","import pandas as pd\n","import numpy as np\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# 카테고리 선택\n","category = input(\"원하는 건강기능식품 종류를 입력해주세요.\\n\\n 건강기능식품 종류: 아연, 비타민, 유산균, 오메가3, 단백질 中 \\t\")\n","\n","if category == '아연':\n","    df = df_zinc\n","elif category == '비타민':\n","    df = df_vitamin\n","elif category == '유산균':\n","    df = df_probiotics\n","elif category == '오메가3':\n","    df = df_omega3\n","elif category == '단백질':\n","    df = df_protein\n","\n","# iloc과 loc 같게 만들기\n","df = df.reset_index(drop=True)\n","\n","\n","# 3. 검색할 쿼리\n","# 하루 필요한 비타민과 미네랄이 모두 들어있는 제품\n","query = input(\"사용자 프롬프트:\\t\") # 테스트용 문장(바꿔서 해보면 됨)\n","\n","# 4. 쿼리 임베딩 (리뷰 임베딩 모델과 동일한 모델 사용)\n","model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n","query_embedding = model.encode([query])\n","\n","# 5. 코사인 유사도 계산\n","embeddings_matrix = np.array(df['긍정리뷰_임베딩_int'].tolist())\n","similarities = cosine_similarity(query_embedding, embeddings_matrix)[0]\n","\n","# 6. 상위 2개 문장 출력\n","top_n = 2\n","top_indices = similarities.argsort()[-top_n:][::-1]\n","unique_results = []\n","seen_ids = set()\n","\n","for idx in top_indices:\n","    product_id = df.iloc[idx]['고유번호']\n","\n","    if product_id not in seen_ids:\n","        seen_ids.add(product_id)\n","        unique_results.append((idx, similarities[idx]))\n","\n","    if len(unique_results) == top_n:\n","        break\n","\n","# 출력\n","def result(unique_results):\n","    outputs = []\n","    for idx, score in unique_results:\n","        row = df.loc[idx]\n","        outputs.append(\n","            f\"\\n제품명: {row['제품명']} | 고유번호: {row['고유번호']} | 카테고리: {row['카테고리']} \"\n","            f\"| 상세정보: {row['상세정보']} \"\n","            f\"\\n긍정 리뷰: {row['긍정리뷰']} \\n부정 리뷰: {row['부정리뷰']} \"\n","            f\"\\n중립 리뷰: {row['중립리뷰']}\"\n","        )\n","        print(f\"\\n인덱스: {idx} | 유사도: {score:.4f} | 제품명: {row['제품명']} | 고유번호: {row['고유번호']} | 카테고리: {row['카테고리']} \"\n","              f\"| 상세정보: {row['상세정보']} \"\n","              f\"\\n긍정 리뷰: {row['긍정리뷰']}\"\n","             # f\"\\n부정 리뷰: {row['부정리뷰']}\\n중립 리뷰: {row['중립리뷰']}\"\n","        )\n","    return outputs\n","\n","product_result = result(unique_results)"],"metadata":{"id":"eT_vZUvwC6MB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# RAG 구현(LanghChain 기반)"],"metadata":{"id":"A9sR-fkCCw7x"}},{"cell_type":"code","source":["from langchain.llms import HuggingFacePipeline\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.prompts import PromptTemplate\n","from langchain.vectorstores import Chroma\n","from langchain.chains import RetrievalQA\n","from langchain.document_loaders import PyPDFLoader, PyMuPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter"],"metadata":{"id":"J_wuwmBPCxxb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","file_path4 = '/content/drive/MyDrive/임베딩/GCP gemini API 활용/reviews_chunked_embeddings4.csv'\n","\n","df = pd.read_csv(file_path4)"],"metadata":{"id":"6bs4H7RfDLbt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import ast\n","df['긍정리뷰_임베딩_int'] = df['긍정리뷰_임베딩'].apply(ast.literal_eval)\n","\n","condition_zinc = (df.loc[:,'카테고리']=='아연')\n","df_zinc = df.loc[condition_zinc,:]\n","\n","condition_vitamin = (df.loc[:,'카테고리']=='비타민')\n","df_vitamin = df.loc[condition_vitamin,:]\n","\n","condition_probiotics = (df.loc[:,'카테고리']=='유산균')\n","df_probiotics = df.loc[condition_probiotics,:]\n","\n","condition_omega3 = (df.loc[:,'카테고리']=='오메가3')\n","df_omega3 = df.loc[condition_omega3,:]\n","\n","condition_protein = (df.loc[:,'카테고리']=='단백질')\n","df_protein = df.loc[condition_protein,:]"],"metadata":{"id":"kGe936B0DM9F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### PDF Load"],"metadata":{"id":"FDDAIpaQDRW6"}},{"cell_type":"code","source":["import glob\n","\n","pdf_folder = \"/content/drive/MyDrive/RAG/PDF/*.pdf\"\n","pdf_files = glob.glob(pdf_folder)"],"metadata":{"id":"9PSVQLnmDOOv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","# 청크 분할기\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size = 500,\n","    chunk_overlap = 50,\n",")\n","\n","# PDF문서 로드 & 청크 분할\n","all_docs = []\n","\n","for pdf_file in tqdm(pdf_files, desc = \"PDF Load :\"):\n","    loader = PyMuPDFLoader(pdf_file)\n","    docs = loader.load()\n","    all_docs.extend(docs)\n","\n","all_chunks = text_splitter.split_documents(all_docs)\n","\n","print(f\"총 문서 수: {len(all_chunks)}\")"],"metadata":{"id":"bvu5sMU_DS5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["docs = []\n","for i, c in enumerate(all_chunks):\n","    docs.append({\n","        \"id\": f\"doc-{i}\",\n","        \"title\": c.metadata.get(\"source\", \"\"),  # PDF 파일명\n","        \"page\": c.metadata.get(\"page\", -1),    # 페이지 번호\n","        \"text\": c.page_content                 # 실제 텍스트\n","    })"],"metadata":{"id":"iPbmLP-9DVKx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### RAG"],"metadata":{"id":"jLDMWuNxDVj3"}},{"cell_type":"code","source":["import os, json, re, textwrap\n","from typing import List, Dict, Any, Tuple\n","\n","from sentence_transformers import SentenceTransformer, CrossEncoder\n","from sklearn.metrics.pairwise import cosine_similarity\n","from rank_bm25 import BM25Okapi\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","\n","# ==================================================\n","# 0. 데이터/카테고리 선택\n","# ==================================================\n","category = input(\"원하는 건강기능식품 종류를 입력해주세요.\\n\\n 건강기능식품 종류: 아연, 비타민, 유산균, 오메가3, 단백질 中 \\t\")\n","\n","# 각 카테고리별 데이터프레임이 있다고 가정\n","if category == '아연':\n","    df = df_zinc\n","elif category == '비타민':\n","    df = df_vitamin\n","elif category == '유산균':\n","    df = df_probiotics\n","elif category == '오메가3':\n","    df = df_omega3\n","elif category == '단백질':\n","    df = df_protein\n","else:\n","    raise ValueError(\"지원하지 않는 카테고리입니다.\")\n","\n","df = df.reset_index(drop=True)\n","\n","# ==================================================\n","# 1. 리뷰 기반 추천 (임베딩 + 코사인 유사도)\n","# ==================================================\n","embed_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n","\n","def search_product_from_reviews(query: str, df: pd.DataFrame, top_n: int = 2):\n","    query_embedding = embed_model.encode([query])\n","    embeddings_matrix = np.array(df['긍정리뷰_임베딩_int'].tolist())\n","    similarities = cosine_similarity(query_embedding, embeddings_matrix)[0]\n","\n","    top_indices = similarities.argsort()[-top_n:][::-1]\n","    unique_results = []\n","    seen_ids = set()\n","\n","    for idx in top_indices:\n","        product_id = df.iloc[idx]['고유번호']\n","        if product_id not in seen_ids:\n","            seen_ids.add(product_id)\n","            unique_results.append((idx, similarities[idx]))\n","        if len(unique_results) == top_n:\n","            break\n","\n","    return unique_results\n","\n","def product_result(unique_results, df: pd.DataFrame):\n","    outputs = []\n","    for idx, score in unique_results:\n","        row = df.loc[idx]\n","        outputs.append(f\"제품명: {row['제품명']}\")\n","    return outputs\n","\n","# ==================================================\n","# 2. 문서 기반 검색 (BM25 + Dense + RRF + Reranker)\n","# ==================================================\n","docs: List[Dict[str, Any]] = []  # TODO: 실제 문서 리스트 로드\n","\n","EMBEDDING_MODEL = \"BAAI/bge-m3\"\n","RERANKER_MODEL = \"BAAI/bge-reranker-v2-m3\"\n","emb_model_doc = SentenceTransformer(EMBEDDING_MODEL)\n","\n","def simple_tokenize_ko(text: str) -> List[str]:\n","    text = re.sub(r\"[^0-9A-Za-z가-힣%·\\.\\-\\s]\", \" \", text)\n","    return [t for t in text.split() if t]\n","\n","bm25_corpus_tokens = [simple_tokenize_ko(d[\"text\"]) for d in docs]\n","bm25 = BM25Okapi(bm25_corpus_tokens) if docs else None\n","\n","try:\n","    import faiss\n","    use_faiss = True\n","except Exception:\n","    faiss = None\n","    use_faiss = False\n","\n","if docs:\n","    doc_embeddings = emb_model_doc.encode([d[\"text\"] for d in docs], batch_size=64, convert_to_numpy=True, show_progress_bar=True)\n","    if use_faiss:\n","        dim = doc_embeddings.shape[1]\n","        index = faiss.IndexFlatIP(dim)\n","        norms = np.linalg.norm(doc_embeddings, axis=1, keepdims=True) + 1e-12\n","        normed = doc_embeddings / norms\n","        index.add(normed.astype('float32'))\n","    else:\n","        index = None\n","else:\n","    doc_embeddings = np.zeros((0, 384), dtype='float32')\n","    index = None\n","\n","def dense_search(query: str, top_k=40) -> List[Tuple[int, float]]:\n","    if not docs:\n","        return []\n","    q = emb_model_doc.encode([query], convert_to_numpy=True)[0]\n","    q = q / (np.linalg.norm(q) + 1e-12)\n","    if index is not None and use_faiss:\n","        D, I = index.search(q[np.newaxis, :].astype('float32'), top_k)\n","        return [(int(i), float(d)) for i, d in zip(I[0], D[0])]\n","    sims = (doc_embeddings @ q) / (np.linalg.norm(doc_embeddings, axis=1) + 1e-12)\n","    top_idx = np.argsort(-sims)[:top_k]\n","    return [(int(i), float(sims[i])) for i in top_idx]\n","\n","def sparse_search(query: str, top_k=80) -> List[Tuple[int, float]]:\n","    if not docs or bm25 is None:\n","        return []\n","    tokens = simple_tokenize_ko(query)\n","    scores = bm25.get_scores(tokens)\n","    top_idx = np.argsort(-scores)[:top_k]\n","    return [(int(i), float(scores[i])) for i in top_idx]\n","\n","def rrf_fuse(dense: List[Tuple[int, float]], sparse: List[Tuple[int, float]], k: int = 60, top_k: int = 50) -> List[int]:\n","    ranks: Dict[int, float] = {}\n","    for lst in [dense, sparse]:\n","        for rank, (idx, _) in enumerate(lst):\n","            ranks[idx] = ranks.get(idx, 0.0) + 1.0 / (k + rank + 1)\n","    fused = sorted(ranks.items(), key=lambda x: -x[1])[:top_k]\n","    return [idx for idx, _ in fused]\n","\n","try:\n","    reranker = CrossEncoder(RERANKER_MODEL)\n","except Exception:\n","    reranker = None\n","\n","def rerank(query: str, candidate_ids: List[int], top_k=10) -> List[int]:\n","    if not candidate_ids:\n","        return []\n","    pairs = [[query, docs[i][\"text\"]] for i in candidate_ids]\n","    if reranker:\n","        scores = reranker.predict(pairs)\n","    else:\n","        qset = set(simple_tokenize_ko(query))\n","        scores = [len(qset & set(simple_tokenize_ko(docs[i][\"text\"]))) for i in candidate_ids]\n","    order = np.argsort(-np.array(scores))[:top_k]\n","    return [candidate_ids[i] for i in order]\n","\n","def build_context(query: str, max_chars: int = 2000, top_k_dense=40, top_k_sparse=40, top_k_final=8) -> Tuple[str, List[Dict[str, Any]]]:\n","    dense = dense_search(query, top_k=top_k_dense)\n","    sparse = sparse_search(query, top_k=top_k_sparse)\n","    fused_ids = rrf_fuse(dense, sparse, k=60, top_k=50)\n","    final_ids = rerank(query, fused_ids, top_k=top_k_final)\n","\n","    selected = []\n","    total = 0\n","    for i in final_ids:\n","        d = docs[i]\n","        snippet = d[\"text\"][:800]\n","        selected.append({\"id\": d[\"id\"], \"title\": d.get(\"title\", \"\"), \"page\": d.get(\"page\", -1), \"text\": snippet})\n","        total += len(snippet)\n","        if total >= max_chars:\n","            break\n","\n","    ctx_blocks = []\n","    for s in selected:\n","        header = f\"[문서:{s['id']}] 제목:{s['title']} | 페이지:{s['page']}\"\n","        ctx_blocks.append(header + \"\\n\" + s[\"text\"].strip())\n","    context_text = \"\\n\\n\".join(ctx_blocks)\n","    return context_text, selected\n","\n","# ==================================================\n","# 3. LLM 프롬프트 & 파서\n","# ==================================================\n","SCHEMA_JSON = {\n","  \"type\": \"object\",\n","  \"properties\": {\n","    \"사용자 입력\": {\"type\": \"string\"},\n","    \"추천 카테고리\": {\"type\": \"string\"},\n","    \"추천 제품\": {\"type\": \"string\"},\n","    \"전문가의 의견\": {\"type\": \"string\"},\n","    \"근거\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n","    \"참고 문서\": {\"type\": \"array\"}\n","  },\n","  \"required\": [\"사용자 입력\", \"추천 제품\", \"전문가의 의견\"]\n","}\n","\n","FEWSHOT = \"\"\"\n","{\n","  \"사용자 입력\": \"20대에게 추천하는 비타민\",\n","  \"추천 카테고리\": \"비타민\",\n","  \"추천 제품\": \"종합 비타민\",\n","  \"전문가의 의견\": \"20대는 균형 잡힌 영양 섭취가 필요하므로 종합 비타민이 적합합니다.\",\n","  \"근거\": [\"리뷰 기반 유사도 검색 결과\", \"제공 문서 참조\"]\n","}\n","\n","</예시>\n","위는 참고용입니다. 출력 시 예시 내용을 반복하지 말고, 실제 사용자 입력에 맞는 답변만 작성하세요.\n","\n","엄격한 규칙:\n","- 반드시 위의 JSON 키만 사용. 추가 키/주석/머리말 금지.\n","- \"전문가의 의견\"은 제공된 문맥에서만 인용/요약. 모르면 \"정보 부족\"이라고 명시.\n","- 제공된 문맥 밖 정보를 추정하거나 발명 금지.\n","\"\"\"\n","\n","SYSTEM_INSTRUCTIONS = f\"\"\"\n","당신은 영양학 전문가입니다.\n","주어진 리뷰 기반 추천 + 문서 기반 검색을 활용하여 JSON을 생성하세요.\n","절대 문맥 밖 지식으로 확장하지 마세요. 불충분하면 \"정보 부족\"을 사용하세요\n","JSON 스키마:\n","{json.dumps(SCHEMA_JSON, ensure_ascii=False)}\n","\"\"\"\n","\n","MODEL_NAME = os.environ.get(\"HF_LLM\", \"skt/A.X-4.0-Light\")\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, padding_side=\"left\")\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n","    device_map=\"auto\"\n",")\n","textgen = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n","\n","def robust_parse_json(text: str) -> Dict[str, Any]:\n","    m = re.search(r\"\\{[\\s\\S]*\\}\", text)\n","    if m:\n","        cand = m.group(0)\n","        try:\n","            return json.loads(cand)\n","        except Exception:\n","            pass\n","    return {\"사용자 입력\": \"\", \"추천 제품\": \"\", \"전문가의 의견\": \"\", \"근거\": []}\n","\n","# ==================================================\n","# 4. 최종 질의 처리\n","# ==================================================\n","def answer_query(query: str, category: str, max_new_tokens: int = 256, temperature: float = 0.2) -> Dict[str, Any]:\n","    # 리뷰 기반 추천\n","    review_results = search_product_from_reviews(query, df)\n","    products = product_result(review_results, df)\n","\n","    # 문서 기반 검색\n","    context_text, selected = build_context(query)\n","\n","    prompt = f\"\"\"\n","    [시스템]\n","    {SYSTEM_INSTRUCTIONS}\n","\n","    [문맥]\n","    {context_text}\n","\n","    [리뷰 기반 추천]\n","    {products}\n","\n","    [사용자 입력]\n","    {query}\n","\n","    [카테고리]\n","    {category}\n","\n","    [지시]\n","    {FEWSHOT}\n","    \"\"\"\n","\n","    out = textgen(\n","        prompt,\n","        max_new_tokens=max_new_tokens,\n","        do_sample=False,\n","        temperature=temperature,\n","        repetition_penalty=1.1,\n","        eos_token_id=tokenizer.eos_token_id,\n","        pad_token_id=tokenizer.eos_token_id,\n","        return_full_text=False\n","    )[0][\"generated_text\"]\n","\n","    data = robust_parse_json(out)\n","    if not data.get(\"추천 카테고리\"):\n","        data[\"추천 카테고리\"] = category\n","    if not data.get(\"참고 문서\") and selected:\n","        data[\"참고 문서\"] = [{\"title\": s[\"title\"], \"page\": s[\"page\"], \"문서ID\": s[\"id\"]} for s in selected[:3]]\n","    return data\n","\n","# ==================================================\n","# 5. 출력 렌더링\n","# ==================================================\n","def render_ko(data: Dict[str, Any]) -> str:\n","    parts = [\n","        f\"사용자 입력 : {data.get('사용자 입력','')}\",\n","        f\"추천 카테고리 : {data.get('추천 카테고리','')}\",\n","        f\"추천 제품 : {data.get('추천 제품','')}\",\n","        f\"전문가의 의견 : {data.get('전문가의 의견','')}\"\n","    ]\n","    if data.get(\"근거\"):\n","        parts.append(\"근거 : \" + \"; \".join(map(str, data[\"근거\"])))\n","    return \"\\n\".join(parts)\n","\n","# ==================================================\n","# 6. 실행부\n","# ==================================================\n","if __name__ == \"__main__\":\n","    query = input(\"사용자 질문: \")\n","    result = answer_query(query, category)\n","    print(render_ko(result))\n"],"metadata":{"id":"dHj6AkMvDV_9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# RAG 구현(LlamaIndex 기반)"],"metadata":{"id":"-lk0jf8bDd2n"}},{"cell_type":"code","source":["### 필요한 함수 임폴트\n","from llama_index.core.node_parser import SentenceSplitter\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","import os\n","from dotenv import load_dotenv\n","from llama_index.llms.google_genai import GoogleGenAI\n","from llama_index.core.llms import ChatMessage, MessageRole\n","from llama_index.core import Settings\n","from llama_index.core import VectorStoreIndex, Document\n","from llama_index.core import SimpleDirectoryReader\n","import unicodedata\n","from llama_index.core.agent import ReActAgent\n","from llama_index.core.tools import QueryEngineTool, ToolMetadata\n","import json\n","\n","### SentenceSplitter\n","\n","text_splitter = SentenceSplitter(\n","    chunk_size=200,\n","    chunk_overlap=50\n",")\n","\n","### embedding\n","\n","# 임베딩 모델 생성\n","embed_model = HuggingFaceEmbedding(\n","    model_name = 'paraphrase-multilingual-MiniLM-L12-v2',\n","    device='cpu' # gpu가 있다면 'cuda'\n",")\n","\n","### llm\n","\n","# google api key 불러오기\n","google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n","google_api_key = ''\n","\n","\n","# llm 생성\n","llm = GoogleGenAI(\n","    model='gemini-2.5-pro',\n","    request_timeout=120.0,\n","    temperature=0.0,\n","    api_key=google_api_key\n",")\n","\n","### settings\n","\n","# llm, embedding, text_splitter 모델 설정\n","Settings.llm = llm\n","Settings.embed_model = embed_model\n","Settings.text_splitter = text_splitter\n","\n","### index\n","\n","import os\n","import unicodedata\n","\n","# 직접 불러올 파일의 경로를 지정합니다.\n","file_path = \"/content/drive/MyDrive/임베딩/GCP gemini API 활용/성분 효능.txt\"\n","\n","\n","# 파일 경로가 존재하는지 확인합니다.\n","if not os.path.exists(file_path):\n","    raise ValueError(f\"지정된 파일 '{file_path}'을(를) 찾을 수 없습니다.\")\n","\n","# 파일 경로를 리스트에 담아줍니다.\n","files = [file_path]\n","\n","# 이제 'files' 리스트에는 지정된 txt 파일의 경로가 하나만 들어 있습니다.\n","# 이 리스트를 사용하여 문서를 로드하고 RAG를 구축하면 됩니다.\n","print(f\"로드할 파일: {files}\")\n","\n","# 문서 로딩\n","txt_documents = SimpleDirectoryReader(input_files=files).load_data()\n","\n","# document 자료 구조 --> 벡터 인덱스 생성: {'Node':임베딩 벡터,...}\n","'''\n","# VectorStoreIndex.from_documents(documents) 실행\n","# 내부적으로 문서 분할 -> 임베딩 -> 저장이 실행\n","'''\n","\n","txt_index = VectorStoreIndex.from_documents(txt_documents)\n","\n","### query_engine\n","\n","# query_engine 생성\n","txt_engine = txt_index.as_query_engine(similarity_top_k=10, include_metadata=True)\n","\n","### queryenginetool\n","\n","## 도구 생성\n","\n","# pdf_tool 생성\n","txt_tool = QueryEngineTool(\n","        query_engine=txt_engine,\n","        metadata=ToolMetadata(\n","            name='txt_tool',\n","            description='건강기능식품에 들어간 원료의 효능을 알려주는 도구입니다.'\n","        )\n","    )\n","\n","### agent\n","\n","# 시스템 프롬프트 정의\n","react_system_prompt = f\"\"\"\n","당신은 건강기능식품 AI 비서입니다. txt_tool을 반드시 활용하세요.\n","\"\"\"\n","\n","# ReActAgent 생성\n","healthcare_agent = ReActAgent(\n","    tools=[txt_tool],\n","    llm=Settings.llm,\n","    system_prompt=react_system_prompt,\n","    verbose=True\n",")\n","\n","\n","response = await healthcare_agent.run(user_msg=f\"\"\"당신은 소비자에게 건강기능식품 구매 시 꼭 알아야 할 중요한 정보를 전달해주는 전문가입니다.\n","아래에 두가지 제품이 제시되어 있습니다. {product_result}에 있는 '상세정보'와 txt_tool에 있는 원료의 효능 텍스트를 이용하여 두가지 제품에 대한 효능을 요약하세요.\n","효능의 근거를 찾기 위해 txt_tool을 사용하여 관련 txt 문서를 참조해야 합니다.\n","제품 정보에는 고유번호는 적지 마세요.\n","부정 리뷰와 중립 리뷰 내용을 기반으로 제품을 구매하기 전에 사용자가 '주의해야 할 점'을 세 가지로 요약하세요.\n","각 주의할 점은 짧은 문장으로 정리하고, '~가 있으니 주의하세요.'와 같은 형식으로 작성하세요.\n","근거를 찾을 수 없는 경우에는 '출처 없음'이라고 작성하세요.\n","\n","두가지 제품 : {product_result}\n","\n","출력은 반드시 아래 JSON 형식으로 작성해야 합니다:\n","[\n","    {{\n","      \"제품명\": \"...\",\n","      \"제품의 효능\": \"...\",\n","      \"제품 정보\": \"...\",\n","      \"근거\": \"...\" - txt_tool을 참조하세요,\n","      \"긍정 리뷰\": \"...\",\n","      \"주의할 점\": \"...\",\n","      \"요약\": \"...\"\n","    }},\n","    ...\n","  ]\"\"\")\n","print(str(response))"],"metadata":{"id":"BLjWVyRxDgEI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 웹 페이지 구현"],"metadata":{"id":"lLtNlexhDmuu"}},{"cell_type":"code","source":["import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import ast\n","import json\n","import os\n","import re\n","from sklearn.metrics.pairwise import cosine_similarity\n","from llama_index.core.node_parser import SentenceSplitter\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from llama_index.llms.google_genai import GoogleGenAI\n","from llama_index.core import Settings\n","from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n","from dotenv import load_dotenv\n","from typing import Any, Dict, List, Optional, Union\n","\n","# .env 파일 로드 (같은 폴더에 본인의 구글 api 주소를 넣은 .env 파일 생성 확인!)\n","load_dotenv()\n","\n","# --- 1. 초기 설정 및 자원 로딩 함수 ---\n","def safe_parse_embedding(x):\n","    \"\"\"결측치(NaN)나 비정상 문자열을 안전하게 파싱합니다.\"\"\"\n","    try:\n","        return ast.literal_eval(x) if pd.notna(x) else []\n","    except Exception:\n","        return []\n","\n","@st.cache_data(show_spinner=False)\n","def load_data():\n","    \"\"\"CSV 파일을 로드하고 임베딩 데이터를 리스트로 변환합니다.\"\"\"\n","    file_path = 'reviews_chunked_embeddings4.csv' # 파일도 같은 폴더에 있어야 함!\n","    if not os.path.exists(file_path):\n","        st.error(f\"파일을 찾을 수 없습니다: {file_path}\")\n","        st.stop()\n","    df = pd.read_csv(file_path)\n","    df['긍정리뷰_임베딩_int'] = df['긍정리뷰_임베딩'].apply(safe_parse_embedding)\n","    return df\n","\n","@st.cache_resource(show_spinner=False)\n","def load_all_resources():\n","    \"\"\"RAG 인덱스와 필요한 모든 자원을 한 번만 로드합니다.\"\"\"\n","    with st.spinner(\"모델과 데이터를 로드하는 중...\"):\n","        # 임베딩 모델\n","        embed_model = HuggingFaceEmbedding(\n","            model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n","            device='cpu' # GPU가 있다면 'cuda'\n","        )\n","\n","        # LLM\n","        google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n","        if not google_api_key:\n","            st.error(\"GOOGLE_API_KEY 환경 변수가 설정되지 않았습니다.\")\n","            st.stop()\n","        llm = GoogleGenAI(\n","            model='gemini-2.5-pro',\n","            request_timeout=120.0,\n","            temperature=0.0,\n","            api_key=google_api_key\n","        )\n","\n","        # 설정 등록\n","        Settings.llm = llm\n","        Settings.embed_model = embed_model\n","        Settings.text_splitter = SentenceSplitter(chunk_size=200, chunk_overlap=50)\n","\n","        # RAG 데이터 로드 및 인덱싱\n","        txt_path = \"성분 효능.txt\" # 해당 텍스트 파일도 같은 폴더 상에 있는지 확인 바람!\n","        if not os.path.exists(txt_path):\n","            st.error(f\"RAG에 필요한 파일을 찾을 수 없습니다: {txt_path}\")\n","            st.stop()\n","        txt_documents = SimpleDirectoryReader(input_files=[txt_path]).load_data()\n","        txt_index = VectorStoreIndex.from_documents(txt_documents)\n","        txt_engine = txt_index.as_query_engine(similarity_top_k=10, include_metadata=True)\n","\n","    return {\n","        \"df_reviews\": load_data(),\n","        \"llm\": llm,\n","        \"embed_model\": embed_model,\n","        \"txt_engine\": txt_engine\n","    }\n","\n","# --- Helper functions ---\n","def extract_json_from_text(s: str) -> Optional[str]:\n","    \"\"\"텍스트에서 JSON 문자열을 다단계로 추출합니다.\"\"\"\n","    # 1) ```json``` 블록 추출\n","    m = re.search(r'```json\\s*(\\[.*\\])\\s*```', s, re.DOTALL)\n","    if m:\n","        return m.group(1)\n","\n","    # 2) 전체에서 첫 '[' ~ 마지막 ']'까지 추출\n","    first = s.find('[')\n","    last = s.rfind(']')\n","    if first != -1 and last != -1 and last > first:\n","        return s[first:last+1]\n","\n","    # 3) 라인 단위로 조합 시도 (배열 시작/끝 또는 객체 시작)\n","    lines = s.splitlines()\n","    json_lines = [line for line in lines if line.strip().startswith('[') or line.strip().endswith(']') or line.strip().startswith('{') or (line.strip().startswith('\"') and line.strip().endswith(',')) or (line.strip().startswith('}') and line.strip().endswith(','))]\n","\n","    if json_lines:\n","        combined_json = \"\\n\".join(json_lines)\n","        if combined_json.strip():\n","            return combined_json.strip()\n","\n","    return None\n","\n","# --- 2. 코사인 유사도 및 RAG 로직 함수 ---\n","def calculate_recommendations(\n","    filtered_df: pd.DataFrame,\n","    user_query: str,\n","    selected_keywords: List[str],\n","    embed_model: HuggingFaceEmbedding,\n","    top_n: int = 2\n",") -> pd.DataFrame:\n","    \"\"\"\n","    코사인 유사도와 RAG 로직을 기반으로 사용자 쿼리에 가장 적합한\n","    제품을 추천하는 함수.\n","\n","    Args:\n","        filtered_df (pd.DataFrame): '긍정리뷰_임베딩_int' 컬럼을 포함한 데이터프레임.\n","        user_query (str): 사용자의 검색 쿼리.\n","        selected_keywords (List[str]): 사용자가 선택한 카테고리(키워드) 리스트.\n","        embed_model (HuggingFaceEmbedding): 미리 로드된 임베딩 모델 객체.\n","        top_n (int): 추천할 제품의 개수.\n","\n","    Returns:\n","        pd.DataFrame: 추천 제품 정보가 담긴 DataFrame.\n","    \"\"\"\n","    # 1. 인덱스 재설정 및 데이터 복사 (인덱스 에러 해결)\n","    df = filtered_df.reset_index(drop=True)\n","\n","    if df.empty:\n","        return pd.DataFrame()\n","\n","    # 2. 사용자 쿼리 임베딩\n","    combined_query = \" \".join(selected_keywords) + \" \" + user_query\n","    query_embedding = embed_model.get_text_embedding(combined_query.strip())\n","\n","    # 3. 코사인 유사도 계산\n","    embeddings_matrix = np.array(df['긍정리뷰_임베딩_int'].tolist())\n","    similarities = cosine_similarity([query_embedding], embeddings_matrix)[0]\n","\n","    # 4. 각 제품의 가장 높은 유사도 점수를 찾아서 DataFrame에 추가\n","    df['유사도'] = similarities\n","\n","    # 5. 제품별로 가장 높은 유사도를 가진 행을 선택\n","    idx = df.groupby('고유번호')['유사도'].idxmax()\n","    df_unique = df.loc[idx].sort_values(by='유사도', ascending=False)\n","\n","    # 6. 상위 n개 제품만 선택\n","    recommended_df = df_unique.head(top_n).copy()\n","\n","    # 7. 유사도 점수가 0인 경우 추천 제품 없음으로 처리\n","    if recommended_df.empty or recommended_df['유사도'].iloc[0] == 0.0:\n","        return pd.DataFrame()\n","\n","    return recommended_df\n","\n","def answer_query(txt_engine: Any, products_info_json: str) -> Optional[List[Dict[str, Any]]]:\n","    \"\"\"\n","    QueryEngine을 직접 호출하여 전문가 의견을 생성합니다.\n","    \"\"\"\n","    user_prompt = f\"\"\"\n","    당신은 소비자에게 건강기능식품 구매 시 꼭 알아야 할 중요한 정보를 전달해주는 전문가입니다.\n","    **반드시 당신에게 제공된 문서(성분 효능.txt)에 있는 정보만을 사용해야 합니다. 다른 정보는 절대 사용하지 마세요.**\n","\n","    아래에 두가지 제품이 제시되어 있습니다. {products_info_json}에 있는 '상세정보'와 **제공된 문서(성분 효능.txt)에 있는 원료의 효능 텍스트를 이용하여** 두가지 제품에 대한 효능을 요약하세요.\n","    효능의 근거를 찾기 위해 제공된 문서를 사용해야 합니다.\n","    제품 정보에는 고유번호는 적지 마세요.\n","\n","    **각 제품에 대한 긍정, 부정, 중립 리뷰의 실제 내용을 기반으로 각각을 요약해야 합니다.** 만약 리뷰 내용이 없다면 '정보 없음'이라고 명시하세요.\n","\n","    부정 리뷰와 중립 리뷰 내용을 기반으로 제품을 구매하기 전에 사용자가 '주의해야 할 점'을 세 가지로 요약하세요.\n","    각 주의할 점은 짧은 문장으로 정리하고, '~가 있으니 주의하세요.'와 같은 형식으로 작성하세요.\n","    근거를 찾을 수 없는 경우에는 '출처 없음'이라고 작성하세요.\n","\n","    두가지 제품 : {products_info_json}\n","\n","    출력은 반드시 아래 JSON 형식으로 작성해야 합니다:\n","    [\n","        {{\n","          \"제품명\": \"...\",\n","          \"제품의 효능\": \"...\",\n","          \"제품 정보\": \"...\",\n","          \"근거\": \"...\" - 제공된 문서를 참조하세요,\n","          \"긍정 리뷰\": \"...\",\n","          \"부정 리뷰\": \"...\",\n","          \"중립 리뷰\": \"...\",\n","          \"주의할 점\": \"...\",\n","          \"요약\": \"...\"\n","        }},\n","        ...\n","      ]\"\"\"\n","\n","    # 1. QueryEngine 직접 호출\n","    try:\n","        response = txt_engine.query(user_prompt)\n","        response_str = str(response)\n","    except Exception as e:\n","        st.error(f\"쿼리 엔진 호출 중 오류가 발생했습니다: {e}\")\n","        return None\n","\n","    # 2. JSON 파싱\n","    json_str = extract_json_from_text(response_str)\n","\n","    if json_str:\n","        try:\n","            return json.loads(json_str)\n","        except Exception:\n","            pass\n","\n","    # 최종적으로 전체 문자열에서 파싱 시도\n","    try:\n","        return json.loads(response_str)\n","    except (json.JSONDecodeError, SyntaxError) as e:\n","        st.error(\"LLM 응답에서 JSON을 파싱하지 못했습니다.\")\n","        st.json(response_str)\n","        return None\n","\n","# --- 3. Streamlit 앱 메인 UI ---\n","def main():\n","    if \"page\" not in st.session_state:\n","        st.session_state.page = 1\n","        st.session_state.df_reviews = pd.DataFrame()\n","        st.session_state.selected_supplement = None\n","        st.session_state.selected_supplement_name = None\n","        st.session_state.selected_keywords = []\n","        st.session_state.page2_checkbox_states = {}\n","        st.session_state.filtered_data = pd.DataFrame()\n","        st.session_state.user_free_text = \"\"\n","        st.session_state.recommended_products = pd.DataFrame()\n","        st.session_state.supplementary_reviews = pd.DataFrame()\n","        st.session_state.rag_result = None\n","\n","    # 모든 리소스 사전 로드\n","    resources = load_all_resources()\n","    st.session_state.df_reviews = resources.get(\"df_reviews\")\n","    st.session_state.llm = resources.get(\"llm\")\n","    st.session_state.embed_model = resources.get(\"embed_model\")\n","    st.session_state.txt_engine = resources.get(\"txt_engine\")\n","\n","    # --- 페이지별 UI 구성 ---\n","    # Page 1\n","    if st.session_state.page == 1:\n","        st.markdown(\"<h1 style='text-align: center;'>💊 건강식품 추천 챗봇</h1>\", unsafe_allow_html=True)\n","        st.markdown(\"<h5 style='text-align: center;'>리뷰를 기반으로 맞춤형 건강식품을 추천해드립니다.</h5>\", unsafe_allow_html=True)\n","        st.progress(25)\n","        st.markdown(\"단계 **1/4** | 25% 완료\")\n","        st.divider()\n","        st.markdown(\"<h3 style='text-align: center;'>어떤 건강식품을 찾으시나요?</h3>\", unsafe_allow_html=True)\n","\n","        supplements = {\n","            \"단백질 쉐이크\": {\"description\": \"💪 근육 건강 및 운동 후 회복\", \"csv_name\": \"단백질\"},\n","            \"오메가3\": {\"description\": \"🐟 심혈관 건강 및 뇌 기능\", \"csv_name\": \"오메가3\"},\n","            \"종합비타민\": {\"description\": \"🌈 전반적인 영양 균형\", \"csv_name\": \"비타민\"},\n","            \"아연\": {\"description\": \"⚡️ 면역력 및 피부 건강\", \"csv_name\": \"아연\"},\n","            \"유산균\": {\"description\": \"🌿 장 건강 및 소화 기능\", \"csv_name\": \"유산균\"}\n","        }\n","\n","        for supplement_name, data_item in supplements.items():\n","            if st.button(f\"**{supplement_name}**\\n\\n{data_item['description']}\", use_container_width=True, key=supplement_name):\n","                st.session_state.selected_supplement = data_item['csv_name']\n","                st.session_state.selected_supplement_name = supplement_name\n","                st.success(f\"**{supplement_name}**를 선택하셨습니다.\")\n","                st.session_state.page = 2\n","                st.rerun()\n","\n","        st.divider()\n","        col1, col2 = st.columns([0.89, 0.11])\n","        with col1:\n","            st.button(\"이전\", disabled=True)\n","        with col2:\n","            if st.button(\"다음 >\", disabled=not st.session_state.selected_supplement):\n","                if st.session_state.selected_supplement:\n","                    st.session_state.page = 2\n","                    st.rerun()\n","                else:\n","                    st.warning(\"먼저 카테고리를 선택해주세요.\")\n","\n","    # Page 2\n","    elif st.session_state.page == 2:\n","        df_reviews = st.session_state.df_reviews\n","        selected_category = st.session_state.get('selected_supplement', None)\n","        if selected_category and not df_reviews.empty:\n","            st.session_state.filtered_data = df_reviews[df_reviews['카테고리'] == selected_category].copy()\n","            if st.session_state.filtered_data.empty:\n","                st.warning(\"선택하신 카테고리에 대한 데이터가 없습니다. 다른 카테고리를 선택해주세요.\")\n","                st.session_state.page = 1\n","                st.stop()\n","\n","        st.markdown(\"<h1 style='text-align: center;'>💊 건강식품 추천 챗봇</h1>\", unsafe_allow_html=True)\n","        st.markdown(\"<h5 style='text-align: center;'>리뷰를 기반으로 맞춤형 건강식품을 추천해드립니다.</h5>\", unsafe_allow_html=True)\n","        st.progress(50)\n","        st.markdown(\"단계 **2/4** | 50% 완료\")\n","        st.divider()\n","        st.markdown(\"<h3 style='text-align: center;'>주요 관심사를 선택해주세요 (복수 선택 가능)</h3>\", unsafe_allow_html=True)\n","\n","        supplement_keywords = {\n","            \"단백질\": [\"근육 증가\", \"맛있는\", \"대용량\", \"목 넘김이 편한\"],\n","            \"오메가3\": [\"심혈관 건강\", \"관절 건강\", \"알약 크기\", \"생선 맛 안나는\"],\n","            \"비타민\": [\"피로 회복\", \"브랜드 신뢰성\", \"알약 크기\", \"고함량\"],\n","            \"아연\": [\"면역력 강화\", \"알약 크기\", \"하루 섭취량\", \"부작용 없는\"],\n","            \"유산균\": [\"장 건강\", \"소화 개선\", \"활력 증진\", \"배변 활동\"],\n","        }\n","        selected_supplement = st.session_state.get('selected_supplement', None)\n","        keywords = supplement_keywords.get(selected_supplement, [])\n","        selected_keywords = []\n","\n","        cols = st.columns(2)\n","        for i, keyword in enumerate(keywords):\n","            col_index = i % 2\n","            with cols[col_index]:\n","                if f\"chkbox_{keyword}\" not in st.session_state.page2_checkbox_states:\n","                    st.session_state.page2_checkbox_states[f\"chkbox_{keyword}\"] = False\n","                is_checked = st.checkbox(\n","                    label=keyword,\n","                    key=f\"chkbox_{keyword}\",\n","                    value=st.session_state.page2_checkbox_states[f\"chkbox_{keyword}\"]\n","                )\n","                if is_checked:\n","                    selected_keywords.append(keyword)\n","\n","        st.session_state.selected_keywords = selected_keywords\n","        st.divider()\n","        col1, col2 = st.columns([0.89, 0.11])\n","        with col1:\n","            if st.button(\"이전\"):\n","                st.session_state.page = 1\n","                st.rerun()\n","        with col2:\n","            if st.button(\"다음 >\"):\n","                if st.session_state.selected_keywords:\n","                    st.session_state.page = 3\n","                    st.rerun()\n","                else:\n","                    st.warning(\"하나 이상의 관심사를 선택해주세요.\")\n","\n","    # Page 3\n","    elif st.session_state.page == 3:\n","        st.markdown(\"<h1 style='text-align: center;'>💊 건강식품 추천 챗봇</h1>\", unsafe_allow_html=True)\n","        st.markdown(\"<h5 style='text-align: center;'>리뷰를 기반으로 맞춤형 건강식품을 추천해드립니다.</h5>\", unsafe_allow_html=True)\n","        st.progress(75)\n","        st.markdown(\"단계 **3/4** | 75% 완료\")\n","        st.divider()\n","        st.markdown(\n","            \"\"\"\n","            <style>\n","            .stTextArea > label { display: none; }\n","            </style>\n","            \"\"\",\n","            unsafe_allow_html=True\n","        )\n","        st.markdown(\"<h3 style='text-align: center;'>추가 요청사항을 자유롭게 입력해주세요</h3>\", unsafe_allow_html=True)\n","        st.session_state.user_free_text = st.text_area(\n","            label=\"질문 입력창\",\n","            placeholder=\"예: 알레르기가 있어서 특정 성분은 피하고 싶어요,\",\n","            height=150,\n","            value=st.session_state.user_free_text,\n","            key=\"user_input_text\"\n","        )\n","        st.markdown(\"<small>선택사항입니다. 이 단계는 건너뛸 수 있습니다.</small>\", unsafe_allow_html=True)\n","        st.divider()\n","        col1, col2 = st.columns([0.86, 0.14])\n","        with col1:\n","            if st.button(\"이전\"):\n","                st.session_state.page = 2\n","                st.rerun()\n","        with col2:\n","            if st.button(\"추천 받기\"):\n","                if st.session_state.filtered_data.empty:\n","                    st.warning(\"선택하신 카테고리에 대한 리뷰 데이터가 없습니다. 다른 카테고리를 선택해주세요.\")\n","                    st.stop()\n","\n","                # 사용자 쿼리 조합\n","                user_query = st.session_state.user_free_text.strip()\n","\n","                if not st.session_state.selected_keywords and not user_query:\n","                    st.warning(\"관심사 또는 추가 요청사항을 입력해주세요.\")\n","                    st.stop()\n","\n","                with st.spinner(\"최적의 제품을 찾고 있습니다...\"):\n","                    recommended_products = calculate_recommendations(\n","                        st.session_state.filtered_data,\n","                        user_query,\n","                        st.session_state.selected_keywords,\n","                        st.session_state.embed_model\n","                    )\n","                    st.session_state.recommended_products = recommended_products\n","\n","                # --- 이 부분을 추가/수정해주세요! ---\n","                if recommended_products.empty:\n","                    st.warning(\"선택하신 조건에 맞는 추천 제품을 찾을 수 없습니다. 조건을 완화하거나 다른 키워드를 시도해보세요.\")\n","                    st.session_state.recommended_products = recommended_products # 빈 DataFrame 저장\n","                    st.session_state.rag_result = None # RAG 결과도 초기화\n","                    st.session_state.page = 4\n","                    st.rerun()\n","\n","                with st.spinner(\"전문가 의견을 생성 중...\"):\n","                    products_info_list = []\n","                    for _, product_row in recommended_products.iterrows():\n","                        all_reviews = st.session_state.df_reviews[st.session_state.df_reviews['제품명'] == product_row['제품명']]\n","                        negative_reviews = ' '.join(all_reviews['부정리뷰'].dropna().astype(str).tolist())\n","                        neutral_reviews = ' '.join(all_reviews['중립리뷰'].dropna().astype(str).tolist())\n","\n","                        products_info_list.append({\n","                            \"제품명\": product_row['제품명'],\n","                            \"고유번호\": product_row['고유번호'],\n","                            \"상세정보\": product_row['상세정보'],\n","                            \"긍정리뷰\": product_row['긍정리뷰'],\n","                            \"부정리뷰\": negative_reviews,\n","                            \"중립리뷰\": neutral_reviews,\n","                            \"카테고리\": product_row['카테고리']\n","                        })\n","\n","                    rag_result = answer_query(\n","                        st.session_state.txt_engine,\n","                        json.dumps(products_info_list, ensure_ascii=False)\n","                    )\n","\n","                    st.session_state.rag_result = rag_result\n","                    st.session_state.page = 4\n","                    st.rerun()\n","\n","    # Page 4\n","    elif st.session_state.page == 4:\n","        st.markdown(\"<h1 style='text-align: center;'>건강식품 추천 결과</h1>\", unsafe_allow_html=True)\n","        col1, col2 = st.columns([0.8, 0.2])\n","\n","        with col2:\n","            if st.button(\"다시 검색\", use_container_width=True):\n","                st.session_state.page = 1\n","                st.session_state.selected_supplement = None\n","                st.session_state.selected_supplement_name = None\n","                st.session_state.selected_keywords = []\n","                st.session_state.page2_checkbox_states = {}\n","                st.session_state.filtered_data = pd.DataFrame()\n","                st.session_state.user_free_text = \"\"\n","                st.session_state.recommended_products = pd.DataFrame()\n","                st.session_state.rag_result = None\n","                st.rerun()\n","\n","        st.progress(100)\n","        st.markdown(\"단계 **4/4** | 100% 완료\")\n","        st.divider()\n","\n","        st.markdown(\"### 👨‍💼 사용자 정보\")\n","        with st.container():\n","            st.markdown(\"<div style='border:1px solid #eee; padding:12px; border-radius:8px'>\", unsafe_allow_html=True)\n","            st.markdown(f\"**관심 제품:** {st.session_state.get('selected_supplement_name', '선택되지 않음')}\")\n","            st.markdown(f\"**관심사:** {', '.join(st.session_state.get('selected_keywords', []))}\")\n","            if st.session_state.get('user_free_text'):\n","                st.markdown(f\"**추가 요청사항:** {st.session_state.user_free_text}\")\n","            st.markdown(\"</div>\", unsafe_allow_html=True)\n","\n","        st.markdown(\"### 🧑‍⚕️ 추천 제품 및 전문가 의견\") # 제목 변경\n","        with st.container():\n","            st.markdown(\"<div style='border:1px solid #eee; padding:12px; border-radius:8px'>\", unsafe_allow_html=True)\n","            rag_result = st.session_state.get('rag_result', None)\n","            if rag_result and isinstance(rag_result, list):\n","                for product_data in rag_result:\n","                    if '제품명' in product_data:\n","                        st.markdown(f\"#### {product_data.get('제품명', '제품명 없음')}\")\n","                        st.markdown(f\"**제품의 효능:** {product_data.get('제품의 효능', '정보 없음')}\")\n","                        st.markdown(f\"**제품 정보:** {product_data.get('제품 정보', '정보 없음')}\")\n","                        st.markdown(f\"**근거:** {product_data.get('근거', '출처 없음')}\")\n","                        st.markdown(f\"**요약:** {product_data.get('요약', '정보 없음')}\")\n","                        st.markdown(\"---\")\n","                        st.markdown(\"##### 📝 참고할만한 리뷰들\")\n","                        st.markdown(f\"- **긍정 리뷰**: {product_data.get('긍정 리뷰', '정보 없음')}\")\n","                        st.markdown(f\"- **부정 리뷰**: {product_data.get('부정 리뷰', '정보 없음')}\")\n","                        st.markdown(f\"- **중립 리뷰**: {product_data.get('중립 리뷰', '정보 없음')}\")\n","                        st.markdown(f\"**주의할 점:**\")\n","                        warnings = product_data.get('주의할 점', [])\n","                        if isinstance(warnings, list):\n","                            for warning in warnings:\n","                                st.markdown(f\"- {warning}\")\n","                        else:\n","                            st.markdown(f\"- {warnings}\")\n","                        st.divider()\n","            else:\n","                st.warning(\"선택하신 조건에 맞는 추천 제품을 찾을 수 없습니다.\") # 추천 제품이 없을 경우 메시지\n","                st.markdown(\"💡 추천 근거: 수집된 15,000개 리뷰를 분석하여 사용자의 관심사와 라이프스타일에 가장 적합한 제품을 추천해드립니다.\", unsafe_allow_html=True)\n","            st.markdown(\"</div>\", unsafe_allow_html=True)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"2cztwthFDoCU"},"execution_count":null,"outputs":[]}]}