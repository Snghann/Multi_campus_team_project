{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOfO2rRuCNJcnI6tRuraBG+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# RAG(LlamaIndex)"],"metadata":{"id":"3xtszOn5FLO1"}},{"cell_type":"code","source":["### 필요한 함수 임폴트\n","import os\n","import json\n","import unicodedata\n","\n","from dotenv import load_dotenv\n","from llama_index.core.node_parser import SentenceSplitter\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from llama_index.llms.google_genai import GoogleGenAI\n","from llama_index.core.llms import ChatMessage, MessageRole\n","from llama_index.core import Settings\n","from llama_index.core import VectorStoreIndex, Document\n","from llama_index.core import SimpleDirectoryReader\n","from llama_index.core.agent import ReActAgent\n","from llama_index.core.tools import QueryEngineTool, ToolMetadata"],"metadata":{"id":"_TVyJ-c-FwOA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cFDETzXWFHA_"},"outputs":[],"source":["### SentenceSplitter\n","\n","text_splitter = SentenceSplitter(\n","    chunk_size=200,\n","    chunk_overlap=50\n",")\n","\n","### embedding\n","\n","# 임베딩 모델 생성\n","embed_model = HuggingFaceEmbedding(\n","    model_name = 'paraphrase-multilingual-MiniLM-L12-v2',\n","    device='cpu'\n",")\n","\n","### llm\n","\n","# google api key 불러오기\n","google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n","google_api_key = ''\n","\n","\n","# llm 생성\n","llm = GoogleGenAI(\n","    model='gemini-2.5-pro',\n","    request_timeout=120.0,\n","    temperature=0.0,\n","    api_key=google_api_key\n",")\n","\n","### settings\n","\n","# llm, embedding, text_splitter 모델 설정\n","Settings.llm = llm\n","Settings.embed_model = embed_model\n","Settings.text_splitter = text_splitter\n","\n","### index\n","\n","import os\n","import unicodedata\n","\n","# 파일 경로가 존재하는지 확인합니다.\n","if not os.path.exists(file_path):\n","    raise ValueError(f\"지정된 파일 '{file_path}'을(를) 찾을 수 없습니다.\")\n","\n","# 파일 경로를 리스트에 담아줍니다.\n","files = [\"/content/drive/MyDrive/임베딩/GCP gemini API 활용/성분 효능.txt\"]\n","\n","# 이제 'files' 리스트에는 지정된 txt 파일의 경로가 하나만 들어 있습니다.\n","# 이 리스트를 사용하여 문서를 로드하고 RAG를 구축하면 됩니다.\n","print(f\"로드할 파일: {files}\")\n","\n","# 문서 로딩\n","txt_documents = SimpleDirectoryReader(input_files=files).load_data()\n","\n","# document 자료 구조 --> 벡터 인덱스 생성: {'Node':임베딩 벡터,...}\n","'''\n","# VectorStoreIndex.from_documents(documents) 실행\n","# 내부적으로 문서 분할 -> 임베딩 -> 저장이 실행\n","'''\n","\n","txt_index = VectorStoreIndex.from_documents(txt_documents)\n","\n","### query_engine\n","\n","# query_engine 생성\n","txt_engine = txt_index.as_query_engine(similarity_top_k=10, include_metadata=True)\n","\n","### queryenginetool\n","\n","## 도구 생성\n","\n","# pdf_tool 생성\n","txt_tool = QueryEngineTool(\n","        query_engine=txt_engine,\n","        metadata=ToolMetadata(\n","            name='txt_tool',\n","            description='건강기능식품에 들어간 원료의 효능을 알려주는 도구입니다.'\n","        )\n","    )\n","\n","### agent\n","\n","# 시스템 프롬프트 정의\n","react_system_prompt = f\"\"\"\n","당신은 건강기능식품 AI 비서입니다. txt_tool을 반드시 활용하세요.\n","\"\"\"\n","\n","# ReActAgent 생성\n","healthcare_agent = ReActAgent(\n","    tools=[txt_tool],\n","    llm=Settings.llm,\n","    system_prompt=react_system_prompt,\n","    verbose=True\n",")\n","\n","\n","response = await healthcare_agent.run(user_msg=f\"\"\"당신은 소비자에게 건강기능식품 구매 시 꼭 알아야 할 중요한 정보를 전달해주는 전문가입니다.\n","아래에 두가지 제품이 제시되어 있습니다. {product_result}에 있는 '상세정보'와 txt_tool에 있는 원료의 효능 텍스트를 이용하여 두가지 제품에 대한 효능을 요약하세요.\n","효능의 근거를 찾기 위해 txt_tool을 사용하여 관련 txt 문서를 참조해야 합니다.\n","제품 정보에는 고유번호는 적지 마세요.\n","부정 리뷰와 중립 리뷰 내용을 기반으로 제품을 구매하기 전에 사용자가 '주의해야 할 점'을 세 가지로 요약하세요.\n","각 주의할 점은 짧은 문장으로 정리하고, '~가 있으니 주의하세요.'와 같은 형식으로 작성하세요.\n","근거를 찾을 수 없는 경우에는 '출처 없음'이라고 작성하세요.\n","\n","두가지 제품 : {product_result}\n","\n","출력은 반드시 아래 JSON 형식으로 작성해야 합니다:\n","[\n","    {{\n","      \"제품명\": \"...\",\n","      \"제품의 효능\": \"...\",\n","      \"제품 정보\": \"...\",\n","      \"근거\": \"...\" - txt_tool을 참조하세요,\n","      \"긍정 리뷰\": \"...\",\n","      \"주의할 점\": \"...\",\n","      \"요약\": \"...\"\n","    }},\n","    ...\n","  ]\"\"\")\n","print(str(response))"]},{"cell_type":"markdown","source":["# RAG(LangChain)"],"metadata":{"id":"AL9L2M-WFkno"}},{"cell_type":"code","source":["import os\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","from langchain.llms import HuggingFacePipeline\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.prompts import PromptTemplate\n","from langchain.vectorstores import Chroma\n","from langchain.chains import RetrievalQA\n","from langchain.document_loaders import PyPDFLoader, PyMuPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter"],"metadata":{"id":"0IZN2tC7Fmg5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","file_path4 = '/content/drive/MyDrive/임베딩/GCP gemini API 활용/reviews_chunked_embeddings4.csv'\n","\n","df = pd.read_csv(file_path4)"],"metadata":{"id":"IMHUwvZiFq3X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import ast\n","df['긍정리뷰_임베딩_int'] = df['긍정리뷰_임베딩'].apply(ast.literal_eval)"],"metadata":{"id":"bdzjEejZF76J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["condition_zinc = (df.loc[:,'카테고리']=='아연')\n","df_zinc = df.loc[condition_zinc,:]\n","\n","condition_vitamin = (df.loc[:,'카테고리']=='비타민')\n","df_vitamin = df.loc[condition_vitamin,:]\n","\n","condition_probiotics = (df.loc[:,'카테고리']=='유산균')\n","df_probiotics = df.loc[condition_probiotics,:]\n","\n","condition_omega3 = (df.loc[:,'카테고리']=='오메가3')\n","df_omega3 = df.loc[condition_omega3,:]\n","\n","condition_protein = (df.loc[:,'카테고리']=='단백질')\n","df_protein = df.loc[condition_protein,:]"],"metadata":{"id":"qzXfWchpF8y3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","\n","pdf_folder = \"/content/drive/MyDrive/RAG/PDF/*.pdf\"\n","pdf_files = glob.glob(pdf_folder)"],"metadata":{"id":"FcD-zdUnF-AU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","# 청크 분할기\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size = 500,\n","    chunk_overlap = 50,\n",")\n","\n","# PDF문서 로드 & 청크 분할\n","all_docs = []\n","\n","for pdf_file in tqdm(pdf_files, desc = \"PDF Load :\"):\n","    loader = PyMuPDFLoader(pdf_file)\n","    docs = loader.load()\n","    all_docs.extend(docs)\n","\n","all_chunks = text_splitter.split_documents(all_docs)\n","\n","print(f\"총 문서 수: {len(all_chunks)}\")"],"metadata":{"id":"9ISv3dN9F_2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["docs = []\n","for i, c in enumerate(all_chunks):\n","    docs.append({\n","        \"id\": f\"doc-{i}\",\n","        \"title\": c.metadata.get(\"source\", \"\"),  # PDF 파일명\n","        \"page\": c.metadata.get(\"page\", -1),    # 페이지 번호\n","        \"text\": c.page_content                 # 실제 텍스트\n","    })"],"metadata":{"id":"XR-kfWyLGDU_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os, json, re, textwrap\n","from typing import List, Dict, Any, Tuple\n","\n","from sentence_transformers import SentenceTransformer, CrossEncoder\n","from sklearn.metrics.pairwise import cosine_similarity\n","from rank_bm25 import BM25Okapi\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","\n","# ==================================================\n","# 0. 데이터/카테고리 선택\n","# ==================================================\n","category = input(\"원하는 건강기능식품 종류를 입력해주세요.\\n\\n 건강기능식품 종류: 아연, 비타민, 유산균, 오메가3, 단백질 中 \\t\")\n","\n","# 각 카테고리별 데이터프레임이 있다고 가정\n","if category == '아연':\n","    df = df_zinc\n","elif category == '비타민':\n","    df = df_vitamin\n","elif category == '유산균':\n","    df = df_probiotics\n","elif category == '오메가3':\n","    df = df_omega3\n","elif category == '단백질':\n","    df = df_protein\n","else:\n","    raise ValueError(\"지원하지 않는 카테고리입니다.\")\n","\n","df = df.reset_index(drop=True)\n","\n","# ==================================================\n","# 1. 리뷰 기반 추천 (임베딩 + 코사인 유사도)\n","# ==================================================\n","embed_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n","\n","def search_product_from_reviews(query: str, df: pd.DataFrame, top_n: int = 2):\n","    query_embedding = embed_model.encode([query])\n","    embeddings_matrix = np.array(df['긍정리뷰_임베딩_int'].tolist())\n","    similarities = cosine_similarity(query_embedding, embeddings_matrix)[0]\n","\n","    top_indices = similarities.argsort()[-top_n:][::-1]\n","    unique_results = []\n","    seen_ids = set()\n","\n","    for idx in top_indices:\n","        product_id = df.iloc[idx]['고유번호']\n","        if product_id not in seen_ids:\n","            seen_ids.add(product_id)\n","            unique_results.append((idx, similarities[idx]))\n","        if len(unique_results) == top_n:\n","            break\n","\n","    return unique_results\n","\n","def product_result(unique_results, df: pd.DataFrame):\n","    outputs = []\n","    for idx, score in unique_results:\n","        row = df.loc[idx]\n","        outputs.append(f\"제품명: {row['제품명']}\")\n","    return outputs\n","\n","# ==================================================\n","# 2. 문서 기반 검색 (BM25 + Dense + RRF + Reranker)\n","# ==================================================\n","docs: List[Dict[str, Any]] = []  # TODO: 실제 문서 리스트 로드\n","\n","EMBEDDING_MODEL = \"BAAI/bge-m3\"\n","RERANKER_MODEL = \"BAAI/bge-reranker-v2-m3\"\n","emb_model_doc = SentenceTransformer(EMBEDDING_MODEL)\n","\n","def simple_tokenize_ko(text: str) -> List[str]:\n","    text = re.sub(r\"[^0-9A-Za-z가-힣%·\\.\\-\\s]\", \" \", text)\n","    return [t for t in text.split() if t]\n","\n","bm25_corpus_tokens = [simple_tokenize_ko(d[\"text\"]) for d in docs]\n","bm25 = BM25Okapi(bm25_corpus_tokens) if docs else None\n","\n","try:\n","    import faiss\n","    use_faiss = True\n","except Exception:\n","    faiss = None\n","    use_faiss = False\n","\n","if docs:\n","    doc_embeddings = emb_model_doc.encode([d[\"text\"] for d in docs], batch_size=64, convert_to_numpy=True, show_progress_bar=True)\n","    if use_faiss:\n","        dim = doc_embeddings.shape[1]\n","        index = faiss.IndexFlatIP(dim)\n","        norms = np.linalg.norm(doc_embeddings, axis=1, keepdims=True) + 1e-12\n","        normed = doc_embeddings / norms\n","        index.add(normed.astype('float32'))\n","    else:\n","        index = None\n","else:\n","    doc_embeddings = np.zeros((0, 384), dtype='float32')\n","    index = None\n","\n","def dense_search(query: str, top_k=40) -> List[Tuple[int, float]]:\n","    if not docs:\n","        return []\n","    q = emb_model_doc.encode([query], convert_to_numpy=True)[0]\n","    q = q / (np.linalg.norm(q) + 1e-12)\n","    if index is not None and use_faiss:\n","        D, I = index.search(q[np.newaxis, :].astype('float32'), top_k)\n","        return [(int(i), float(d)) for i, d in zip(I[0], D[0])]\n","    sims = (doc_embeddings @ q) / (np.linalg.norm(doc_embeddings, axis=1) + 1e-12)\n","    top_idx = np.argsort(-sims)[:top_k]\n","    return [(int(i), float(sims[i])) for i in top_idx]\n","\n","def sparse_search(query: str, top_k=80) -> List[Tuple[int, float]]:\n","    if not docs or bm25 is None:\n","        return []\n","    tokens = simple_tokenize_ko(query)\n","    scores = bm25.get_scores(tokens)\n","    top_idx = np.argsort(-scores)[:top_k]\n","    return [(int(i), float(scores[i])) for i in top_idx]\n","\n","def rrf_fuse(dense: List[Tuple[int, float]], sparse: List[Tuple[int, float]], k: int = 60, top_k: int = 50) -> List[int]:\n","    ranks: Dict[int, float] = {}\n","    for lst in [dense, sparse]:\n","        for rank, (idx, _) in enumerate(lst):\n","            ranks[idx] = ranks.get(idx, 0.0) + 1.0 / (k + rank + 1)\n","    fused = sorted(ranks.items(), key=lambda x: -x[1])[:top_k]\n","    return [idx for idx, _ in fused]\n","\n","try:\n","    reranker = CrossEncoder(RERANKER_MODEL)\n","except Exception:\n","    reranker = None\n","\n","def rerank(query: str, candidate_ids: List[int], top_k=10) -> List[int]:\n","    if not candidate_ids:\n","        return []\n","    pairs = [[query, docs[i][\"text\"]] for i in candidate_ids]\n","    if reranker:\n","        scores = reranker.predict(pairs)\n","    else:\n","        qset = set(simple_tokenize_ko(query))\n","        scores = [len(qset & set(simple_tokenize_ko(docs[i][\"text\"]))) for i in candidate_ids]\n","    order = np.argsort(-np.array(scores))[:top_k]\n","    return [candidate_ids[i] for i in order]\n","\n","def build_context(query: str, max_chars: int = 2000, top_k_dense=40, top_k_sparse=40, top_k_final=8) -> Tuple[str, List[Dict[str, Any]]]:\n","    dense = dense_search(query, top_k=top_k_dense)\n","    sparse = sparse_search(query, top_k=top_k_sparse)\n","    fused_ids = rrf_fuse(dense, sparse, k=60, top_k=50)\n","    final_ids = rerank(query, fused_ids, top_k=top_k_final)\n","\n","    selected = []\n","    total = 0\n","    for i in final_ids:\n","        d = docs[i]\n","        snippet = d[\"text\"][:800]\n","        selected.append({\"id\": d[\"id\"], \"title\": d.get(\"title\", \"\"), \"page\": d.get(\"page\", -1), \"text\": snippet})\n","        total += len(snippet)\n","        if total >= max_chars:\n","            break\n","\n","    ctx_blocks = []\n","    for s in selected:\n","        header = f\"[문서:{s['id']}] 제목:{s['title']} | 페이지:{s['page']}\"\n","        ctx_blocks.append(header + \"\\n\" + s[\"text\"].strip())\n","    context_text = \"\\n\\n\".join(ctx_blocks)\n","    return context_text, selected\n","\n","# ==================================================\n","# 3. LLM 프롬프트 & 파서\n","# ==================================================\n","SCHEMA_JSON = {\n","  \"type\": \"object\",\n","  \"properties\": {\n","    \"사용자 입력\": {\"type\": \"string\"},\n","    \"추천 카테고리\": {\"type\": \"string\"},\n","    \"추천 제품\": {\"type\": \"string\"},\n","    \"전문가의 의견\": {\"type\": \"string\"},\n","    \"근거\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n","    \"참고 문서\": {\"type\": \"array\"}\n","  },\n","  \"required\": [\"사용자 입력\", \"추천 제품\", \"전문가의 의견\"]\n","}\n","\n","FEWSHOT = \"\"\"\n","{\n","  \"사용자 입력\": \"20대에게 추천하는 비타민\",\n","  \"추천 카테고리\": \"비타민\",\n","  \"추천 제품\": \"종합 비타민\",\n","  \"전문가의 의견\": \"20대는 균형 잡힌 영양 섭취가 필요하므로 종합 비타민이 적합합니다.\",\n","  \"근거\": [\"리뷰 기반 유사도 검색 결과\", \"제공 문서 참조\"]\n","}\n","\n","</예시>\n","위는 참고용입니다. 출력 시 예시 내용을 반복하지 말고, 실제 사용자 입력에 맞는 답변만 작성하세요.\n","\n","엄격한 규칙:\n","- 반드시 위의 JSON 키만 사용. 추가 키/주석/머리말 금지.\n","- \"전문가의 의견\"은 제공된 문맥에서만 인용/요약. 모르면 \"정보 부족\"이라고 명시.\n","- 제공된 문맥 밖 정보를 추정하거나 발명 금지.\n","\"\"\"\n","\n","SYSTEM_INSTRUCTIONS = f\"\"\"\n","당신은 영양학 전문가입니다.\n","주어진 리뷰 기반 추천 + 문서 기반 검색을 활용하여 JSON을 생성하세요.\n","절대 문맥 밖 지식으로 확장하지 마세요. 불충분하면 \"정보 부족\"을 사용하세요\n","JSON 스키마:\n","{json.dumps(SCHEMA_JSON, ensure_ascii=False)}\n","\"\"\"\n","\n","MODEL_NAME = os.environ.get(\"HF_LLM\", \"skt/A.X-4.0-Light\")\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, padding_side=\"left\")\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n","    device_map=\"auto\"\n",")\n","textgen = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n","\n","def robust_parse_json(text: str) -> Dict[str, Any]:\n","    m = re.search(r\"\\{[\\s\\S]*\\}\", text)\n","    if m:\n","        cand = m.group(0)\n","        try:\n","            return json.loads(cand)\n","        except Exception:\n","            pass\n","    return {\"사용자 입력\": \"\", \"추천 제품\": \"\", \"전문가의 의견\": \"\", \"근거\": []}\n","\n","# ==================================================\n","# 4. 최종 질의 처리\n","# ==================================================\n","def answer_query(query: str, category: str, max_new_tokens: int = 256, temperature: float = 0.2) -> Dict[str, Any]:\n","    # 리뷰 기반 추천\n","    review_results = search_product_from_reviews(query, df)\n","    products = product_result(review_results, df)\n","\n","    # 문서 기반 검색\n","    context_text, selected = build_context(query)\n","\n","    prompt = f\"\"\"\n","    [시스템]\n","    {SYSTEM_INSTRUCTIONS}\n","\n","    [문맥]\n","    {context_text}\n","\n","    [리뷰 기반 추천]\n","    {products}\n","\n","    [사용자 입력]\n","    {query}\n","\n","    [카테고리]\n","    {category}\n","\n","    [지시]\n","    {FEWSHOT}\n","    \"\"\"\n","\n","    out = textgen(\n","        prompt,\n","        max_new_tokens=max_new_tokens,\n","        do_sample=False,\n","        temperature=temperature,\n","        repetition_penalty=1.1,\n","        eos_token_id=tokenizer.eos_token_id,\n","        pad_token_id=tokenizer.eos_token_id,\n","        return_full_text=False\n","    )[0][\"generated_text\"]\n","\n","    data = robust_parse_json(out)\n","    if not data.get(\"추천 카테고리\"):\n","        data[\"추천 카테고리\"] = category\n","    if not data.get(\"참고 문서\") and selected:\n","        data[\"참고 문서\"] = [{\"title\": s[\"title\"], \"page\": s[\"page\"], \"문서ID\": s[\"id\"]} for s in selected[:3]]\n","    return data\n","\n","# ==================================================\n","# 5. 출력 렌더링\n","# ==================================================\n","def render_ko(data: Dict[str, Any]) -> str:\n","    parts = [\n","        f\"사용자 입력 : {data.get('사용자 입력','')}\",\n","        f\"추천 카테고리 : {data.get('추천 카테고리','')}\",\n","        f\"추천 제품 : {data.get('추천 제품','')}\",\n","        f\"전문가의 의견 : {data.get('전문가의 의견','')}\"\n","    ]\n","    if data.get(\"근거\"):\n","        parts.append(\"근거 : \" + \"; \".join(map(str, data[\"근거\"])))\n","    return \"\\n\".join(parts)\n","\n","# ==================================================\n","# 6. 실행부\n","# ==================================================\n","if __name__ == \"__main__\":\n","    query = input(\"사용자 질문: \")\n","    result = answer_query(query, category)\n","    print(render_ko(result))\n"],"metadata":{"id":"1flZ_lGdGEeN"},"execution_count":null,"outputs":[]}]}